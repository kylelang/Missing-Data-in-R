%%% Title:    Missing Data Stats Camp Course: Multivariate MI
%%% Author:   Kyle M. Lang
%%% Created:  2017-SEP-12
%%% Modified: 2018-OCT-18

\documentclass{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme[%
  pageofpages          = of,
  bullet               = circle,
  titleline            = true,
  alternativetitlepage = true,
  titlepagelogo        = Logo3,
  watermark            = watermarkTiU,
  watermarkheight      = 100px,
  watermarkheightmult  = 4%
]{UVT}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{caption}

%% Ensure styles of `blocks' (used in Definitions, Theorems etc.) follows the
%% UVT-style theme:
\setbeamercolor{block title}{fg = darkblue, bg = white}
\setbeamercolor{block body}{use = block title, bg = block title.bg}

%% Ensure TableOfContents is in UVT-style theme:
\setbeamercolor{section in toc}{fg = darkblue}

%% Don't number broken frames
\setbeamertemplate{frametitle continuation}{}

%% Don't label table captions:
\captionsetup{labelformat = empty}

\title{Multivariate Multiple Imputation}
\subtitle{Stats Camp 2018: Missing Data Analysis}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Tilburg University}
\date{19--21 October 2018}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

%------------------------------------------------------------------------------%



%------------------------------------------------------------------------------%

\begin{frame}[t,plain]
    
  \titlepage
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  
  \begin{itemize}
  \item Discuss the two frameworks for multivariate MI
    \vc
    \begin{itemize}
    \item Fully conditional specification
      \vc
    \item Joint Modeling
    \end{itemize}
    \vb
  \item Show a manual \textsf{R} example of each approach
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Joint Modeling vs. Fully Conditional Specification}

  When imputing with \emph{Joint Modeling} approaches, the missing data are 
  replaced by samples from the joint posterior predictive distribution.
  \vb
  \begin{itemize}
    \item To impute $X$, $Y$, and $Z$, we draw:
      \begin{align*}
        X, Y, Z \sim P(X, Y, Z | \theta)
      \end{align*}
  \end{itemize}
  \vb
  With \emph{Fully Conditional Specification}, the missing data are replaced 
  with samples from the conditional posterior predictive distribution of each 
  incomplete variable.
  \vb
  \begin{itemize}
  \item To impute $X$, $Y$, and $Z$, we draw:
    \begin{align*}
      X &\sim P(X | Y, Z, \theta_X)\\
      Y &\sim P(Y | X, Z, \theta_Y)\\
      Z &\sim P(Z | Y, X, \theta_Z)
    \end{align*}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Joint Modeling: Strengths}
  
  When correctly implemented, joint modeling approaches are guaranteed to 
  produce \emph{Bayesianly proper} imputations.
  \vb
  \begin{itemize}
  \item The sufficient condition for \emph{properness} is that the imputations 
    are randomly sampled from the correctly specified joint posterior predictive 
    distribution of missing data.
    \vc
    \begin{itemize}
    \item This is the defining characteristic of joint modeling methods.
    \end{itemize}
  \end{itemize}
  \va
  When using the correct distribution imputations produced by joint modeling 
  methods will be the best possible imputations.
  \begin{itemize}
  \item Unbiased parameter estimates
  \item Well-calibrated sampling variability
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Joint Modeling: Weaknesses}
  
  Joint modeling approaches are very computationally demanding.
  \vc
  \begin{itemize}
  \item The computational burden increases with the number of incomplete 
    variables.
  \end{itemize}
  \va
  Joint modeling approaches are only applicable when the joint distribution of 
  all incomplete variables follows a known form.
  \vc
  \begin{itemize}
  \item Mixes of continuous and categorical variables are very difficult to 
    accommodate.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Fully Conditional Specification: Strengths}
  
  FCS is computationally simpler than JM approaches.
  \vc
  \begin{itemize}
  \item FCS only samples from a series of univariate distributions, not large 
    joint distributions.
  \end{itemize}
  \va 
  FCS approaches can create imputations for variables that don't have a sensible 
  joint distribution.
  \vc
  \begin{itemize}
  \item Mixes of continuous and categorical variables are easily treated with 
    FCS.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Fully Conditional Specification: Weaknesses}

  FCS will usually be slower than JM.
  \vc
  \begin{itemize}
  \item Each variable is given its own fully parameterized distribution, even if 
    that granularity is unnecessary.
  \end{itemize}
  \va
  When the incomplete variables don't have a known joint distribution, we don't 
  have theoretical support for the validity of FCS.
  \vc
  \begin{itemize}
  \item There is, however, a large degree of empirical support for the 
    tenability of the FCS approach.
  \item In practice, we will usually use FCS since real data rarely arise from a 
    known joint distribution.
  \end{itemize}
  
\end{frame}
  
%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Up to this point, most of the models we've explored could be approximated by 
  sampling directly from their posterior distributions.
  \vc
  \begin{itemize}
    \item This won't be true with arbitrary, multivariate missing data
  \end{itemize}
  \va 
  To make inference regarding a multivariate distribution with multiple, 
  interrelated, unknown parameters, we can use \emph{Gibbs sampling}.
  \vc
  \begin{itemize}
  \item Sample from the conditional distribution of each parameter, conditioning 
    on the current best guesses of all other parameters.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Suppose the following:
  \vb
  \begin{enumerate}
  \item I want to make some inference about the tri-variate mean of
    $X, Y, Z = \mu_X, \mu_Y, \mu_Z \sim P(\mu | \theta)$
    \vb
  \item $P(\mu | \theta)$ is super hairy and difficult to sample
    \vb
  \item The conditional distributions:
    $P(\mu_X | \hat{\mu}_Y, \hat{\mu}_Z, \theta)$,
    $P(\mu_Y | \hat{\mu}_X, \hat{\mu}_Z, \theta)$, and
    $P(\mu_Z | \hat{\mu}_X, \hat{\mu}_Y, \theta)$ are easily sampled.
  \end{enumerate}
  \va
  Then I can approximate the full joint distribution
  $P(\mu | \theta)$ by repeatedly and sequentially sampling from
  $P(\mu_X | \hat{\mu}_Y, \hat{\mu}_Z, \theta)$, $P(\mu_Y |
  \hat{\mu}_X, \hat{\mu}_Z, \theta)$, and $P(\mu_Z | \hat{\mu}_X,
  \hat{\mu}_Y, \theta)$.

\end{frame}
  
%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Starting with initial guesses of $\mu_Y$, $\hat{\mu}_Y^{(0)}$, and
  $\mu_Z$, $\hat{\mu}_Z^{(0)}$, and assuming $\theta$ is known, Gibbs
  sampling proceeds as follows:
  \begin{align*}
    \hat{\mu}_X^{(1)} &\sim P(\mu_X | \hat{\mu}_Y^{(0)}, \hat{\mu}_Z^{(0)}, \theta)\\
    \hat{\mu}_Y^{(1)} &\sim P(\mu_Y | \hat{\mu}_X^{(1)}, \hat{\mu}_Z^{(0)}, \theta)\\
    \hat{\mu}_Z^{(1)} &\sim P(\mu_Z | \hat{\mu}_Y^{(1)}, \hat{\mu}_X^{(1)}, \theta)\\
    \\
    \hat{\mu}_X^{(2)} &\sim P(\mu_X | \hat{\mu}_Y^{(1)}, \hat{\mu}_Z^{(1)}, \theta)\\
    \hat{\mu}_Y^{(2)} &\sim P(\mu_Y | \hat{\mu}_X^{(2)}, \hat{\mu}_Z^{(1)}, \theta)\\
    \hat{\mu}_Z^{(2)} &\sim P(\mu_Z | \hat{\mu}_Y^{(2)}, \hat{\mu}_X^{(2)}, \theta)
  \end{align*}
  \vspace{-40pt}
  \begin{center}\huge{$\vdots$}\end{center}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Why do we care?}
  
  Multivariate MI employs the same logic as Gibbs sampling.
  \vb
  \begin{itemize}
  \item The imputations are created by conditioning on the current estimates of 
    the imputation model parameters.
    \vb
  \item The imputation model parameters are updated by conditioning on the most 
    recent imputations.
    \vb
  \item With FCS, each variable is imputed by conditioning on the most recent 
    imputations of all other variables.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Procedure: Fully Conditional Specification}
  
  \begin{enumerate}
  \item Fill the missing data with reasonable guesses.
    \vb
  \item For each incomplete variable, do a single iteration of univariate 
    Bayesian MI (e.g., as seen in the last set of slides). \label{eiStep}
    \vb
    \begin{itemize}
    \item After each variable on the data set is so treated, we've completed one 
      iteration.
    \end{itemize}
    \vc
  \item Repeat Step \ref{eiStep} many times.
    \vb
  \item After the imputation model parameters stabilize, save $M$ imputed data 
    sets.
  \end{enumerate}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Simulate some data:}
\hlstd{simData} \hlkwb{<-}
    \hlkwd{simCovData}\hlstd{(}\hlkwc{nObs} \hlstd{=} \hlnum{1000}\hlstd{,} \hlkwc{sigma} \hlstd{=} \hlnum{0.25}\hlstd{,} \hlkwc{nVars} \hlstd{=} \hlnum{4}\hlstd{)}

\hlkwd{head}\hlstd{(simData,} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
##             x1         x2          x3          x4
## 1   0.06313632 -1.4057704 -0.01709217  1.47929405
## 2  -1.31592547  1.2970920 -0.83500777 -0.44528158
## 3  -0.30997023  0.9782580  0.02731853  0.35507390
## 4   0.06927787  0.1836032  0.68794409  0.08049987
## 5  -0.99354894 -0.3038956  0.80918329 -1.72143555
## 6   0.36828016 -0.9423245  1.05155348 -0.11078496
## 7   1.33333163  2.3089780  1.47203000  0.85877495
## 8  -0.02759718  0.1714383  0.18927909  0.28627771
## 9   2.37929433  2.5080935  2.18344726  1.56980951
## 10  0.31841502  0.7886025  0.73658136  0.39445970
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Example: Fully Conditional Specification}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Impose missing:}
\hlstd{targets}  \hlkwb{<-} \hlkwd{paste0}\hlstd{(}\hlstr{"x"}\hlstd{,} \hlnum{1} \hlopt{:} \hlnum{3}\hlstd{)}
\hlstd{missData} \hlkwb{<-}
    \hlkwd{imposeMissData}\hlstd{(}\hlkwc{data}    \hlstd{= simData,}
                   \hlkwc{targets} \hlstd{=} \hlkwd{list}\hlstd{(}\hlkwc{mar} \hlstd{= targets),}
                   \hlkwc{preds}   \hlstd{=} \hlstr{"x4"}\hlstd{,}
                   \hlkwc{pm}      \hlstd{=} \hlnum{0.3}\hlstd{,}
                   \hlkwc{snr}     \hlstd{=} \hlnum{5.0}\hlstd{,}
                   \hlkwc{pattern} \hlstd{=} \hlkwd{c}\hlstd{(}\hlkwc{x1} \hlstd{=} \hlstr{"low"}\hlstd{,}
                               \hlkwc{x2} \hlstd{=} \hlstr{"center"}\hlstd{,}
                               \hlkwc{x3} \hlstd{=} \hlstr{"high"}\hlstd{)}
                   \hlstd{)}\hlopt{$}\hlstd{data}
\end{alltt}
\end{kframe}
\end{knitrout}

\pagebreak

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{head}\hlstd{(missData,} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
##             x1         x2          x3          x4
## 1   0.06313632 -1.4057704          NA  1.47929405
## 2           NA  1.2970920 -0.83500777 -0.44528158
## 3  -0.30997023  0.9782580  0.02731853  0.35507390
## 4   0.06927787         NA  0.68794409  0.08049987
## 5           NA -0.3038956  0.80918329 -1.72143555
## 6   0.36828016         NA  1.05155348 -0.11078496
## 7   1.33333163  2.3089780          NA  0.85877495
## 8  -0.02759718  0.1714383  0.18927909  0.28627771
## 9   2.37929433  2.5080935          NA  1.56980951
## 10  0.31841502         NA  0.73658136  0.39445970
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Define iteration numbers:}
\hlstd{nImps} \hlkwb{<-} \hlnum{100}
\hlstd{nBurn} \hlkwb{<-} \hlnum{500}
\hlstd{nSams} \hlkwb{<-} \hlstd{nBurn} \hlopt{+} \hlstd{nImps}

\hlcom{## Summarize missingness:}
\hlstd{rMat} \hlkwb{<-} \hlopt{!}\hlkwd{is.na}\hlstd{(missData)}
\hlstd{nObs} \hlkwb{<-} \hlkwd{colSums}\hlstd{(rMat)}
\hlstd{nMis} \hlkwb{<-} \hlkwd{colSums}\hlstd{(}\hlopt{!}\hlstd{rMat)}

\hlcom{## Fill the missingness with initial (bad) guesses:}
\hlstd{mean0}  \hlkwb{<-} \hlkwd{colMeans}\hlstd{(missData,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlstd{sigma0} \hlkwb{<-} \hlkwd{cov}\hlstd{(missData,} \hlkwc{use} \hlstd{=} \hlstr{"pairwise"}\hlstd{)}
\hlstd{draws0} \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlkwd{nrow}\hlstd{(missData), mean0, sigma0)}

\hlstd{impData}        \hlkwb{<-} \hlstd{missData}
\hlstd{impData[}\hlopt{!}\hlstd{rMat]} \hlkwb{<-} \hlstd{draws0[}\hlopt{!}\hlstd{rMat]}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Define an elementary imputation function:
  
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{eif} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{rVec}\hlstd{,} \hlkwc{v}\hlstd{) \{}
    \hlcom{## Get the expected betas:}
    \hlstd{fit}  \hlkwb{<-} \hlkwd{lm}\hlstd{(}\hlkwd{paste}\hlstd{(v,} \hlstr{"~ ."}\hlstd{),} \hlkwc{data} \hlstd{= data[rVec, ])}
    \hlstd{beta} \hlkwb{<-} \hlkwd{coef}\hlstd{(fit)}

    \hlcom{## Sample sigma:}
    \hlstd{sigScale} \hlkwb{<-} \hlstd{(}\hlnum{1} \hlopt{/} \hlstd{fit}\hlopt{$}\hlstd{df)} \hlopt{*} \hlkwd{crossprod}\hlstd{(}\hlkwd{resid}\hlstd{(fit))}
    \hlstd{sigmaSam} \hlkwb{<-} \hlkwd{rinvchisq}\hlstd{(}\hlnum{1}\hlstd{,} \hlkwc{df} \hlstd{= fit}\hlopt{$}\hlstd{df,} \hlkwc{scale} \hlstd{= sigScale)}

    \hlcom{## Sample beta:}
    \hlstd{betaVar} \hlkwb{<-} \hlstd{sigmaSam} \hlopt{*} \hlkwd{solve}\hlstd{(}\hlkwd{crossprod}\hlstd{(}\hlkwd{qr.X}\hlstd{(fit}\hlopt{$}\hlstd{qr)))}
    \hlstd{betaSam} \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlnum{1}\hlstd{,} \hlkwc{mean} \hlstd{= beta,} \hlkwc{sigma} \hlstd{= betaVar)}

    \hlcom{## Return a randomly sampled imputation:}
    \hlkwd{matrix}\hlstd{(}\hlkwd{cbind}\hlstd{(}\hlnum{1}\hlstd{, data[}\hlopt{!}\hlstd{rVec, ]))} \hlopt{%*%} \hlstd{betaSam} \hlopt{+}
        \hlkwd{rnorm}\hlstd{(}\hlkwd{sum}\hlstd{(}\hlopt{!}\hlstd{rVec),} \hlnum{0}\hlstd{,} \hlkwd{sqrt}\hlstd{(sigmaSam))}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Apply the elementary imputation function to each incomplete variable:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Iterate through the FCS algorithm:}
\hlstd{impList} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(s} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nSams) \{}
    \hlkwa{for}\hlstd{(v} \hlkwa{in} \hlstd{targets) \{}
        \hlstd{rVec}              \hlkwb{<-} \hlstd{rMat[ , v]}
        \hlstd{impData[}\hlopt{!}\hlstd{rVec, v]} \hlkwb{<-} \hlkwd{eif}\hlstd{(impData, rVec, v)}
    \hlstd{\}}

    \hlcom{## If the chains are burnt-in, save imputed datasets:}
    \hlkwa{if}\hlstd{(s} \hlopt{>} \hlstd{nBurn) impList[[s} \hlopt{-} \hlstd{nBurn]]} \hlkwb{<-} \hlstd{impData}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Analyze the multiply imputed datasets:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## First, our manual version:}
\hlstd{fits1} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,} \hlkwc{data} \hlstd{= x)}
                \hlstd{)}
\hlstd{pool1} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits1)}

\hlcom{## Do the same analysis with mice():}
\hlstd{miceOut} \hlkwb{<-} \hlkwd{mice}\hlstd{(}\hlkwc{data}      \hlstd{= missData,}
                \hlkwc{m}         \hlstd{=} \hlnum{100}\hlstd{,}
                \hlkwc{method}    \hlstd{=} \hlstr{"norm"}\hlstd{,}
                \hlkwc{printFlag} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\hlstd{fits2} \hlkwb{<-} \hlkwd{with}\hlstd{(miceOut,} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3))}
\hlstd{pool2} \hlkwb{<-} \hlkwd{pool}\hlstd{(fits2)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Example: Fully Conditional Specification}

  Compare approaches:\\
  \vb
  
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Fri Oct 19 00:20:17 2018
\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{rlllll}
  \toprule
 & Est & SE & t & p & FMI \\ 
  \midrule
(Intercept) & 0.023 & 0.034 & 0.675 & 0.5 & 0.253 \\ 
  x2 & 0.172 & 0.04 & 4.35 & $<$0.001 & 0.473 \\ 
  x3 & 0.211 & 0.042 & 5.032 & $<$0.001 & 0.502 \\ 
   \bottomrule
\end{tabular}
}
\caption{Manual Version} 
\end{table}
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Fri Oct 19 00:20:17 2018
\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{rlllll}
  \toprule
 & Est & SE & t & p & FMI \\ 
  \midrule
(Intercept) & 0.019 & 0.044 & 0.44 & 0.66 & 0.568 \\ 
  x2 & 0.169 & 0.044 & 3.791 & $<$0.001 & 0.584 \\ 
  x3 & 0.212 & 0.05 & 4.217 & $<$0.001 & 0.656 \\ 
   \bottomrule
\end{tabular}
}
\caption{MICE Version} 
\end{table}


\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Definition of Regression Parameters}
  
  So far, we've been using the least-squares estimates of $\alpha$, $\beta$, and 
  $\sigma^2$ to parameterize our posterior distributions.
  \vc
  \begin{itemize}
  \item We can also define the parameters in terms of sufficient statistics.
  \end{itemize}
  \vb
  Given $\mu$ and $\Sigma$, we can define all of our regression moments as:
  \begin{align*}
    \beta &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\\
    &= \text{Cov}(\mathbf{X})^{-1} \text{Cov}(\mathbf{X}, \mathbf{Y})\\
    \alpha &= \mu_Y - \beta^T \mu_X\\
    \Sigma_{\varepsilon} &= \Sigma_Y - \beta^T \Sigma_X \beta
  \end{align*}
  These definitions are crucial for JM approaches.
  \begin{itemize}
  \item Within the subset of data define by a given response pattern, the 
    outcome variables will be entirely missing.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Multivariate Bayesian Regression}
  
  Previously, we saw examples of univariate Bayesian regression which used the 
  following model:
  \begin{align*}
    \beta &\sim \text{MVN} \left( \hat{\beta}_{ls}, ~ 
    \sigma^2 (\mathbf{X}^T \mathbf{X})^{-1} \right)\\
    \sigma^2 &\sim \text{Inv-}\chi^2 \left(N - P, MSE \right)
  \end{align*}
  We can directly extend the above to the multivariate case:
  \begin{align*}
    \Sigma^{(i)} &\sim \text{Inv-W} \left(N - 1, (N - 1) \Sigma^{(i - 1)} \right)\\
    \mu^{(i)} &\sim \text{MVN} \left(\mu^{(i - 1)}, N^{-1}\Sigma^{(i)} \right)
  \end{align*}
  We get $\alpha$, $\beta$, and $\Sigma_{\varepsilon}$ via the calculations on the 
  preceding slide
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Procedure: Joint Modeling}
  
  \begin{enumerate}
  \item Partition the incomplete data by response pattern.
    \begin{itemize}
    \item Produce $S$ subsets wherein each row shares the same response pattern.
    \end{itemize}
    \vc
  \item Provide initial guesses for $\mu$ and $\Sigma$.
    \vb
  \item Within each subset, use the current guesses of $\mu$ and $\Sigma$ to 
    generate imputations via multivariate Bayesian regression. \label{iStep}
    \vb
  \item Use the filled-in data matrix to updated the sufficient statistics.
    \label{pStep}
    \vb
  \item Repeat Steps \ref{iStep} and \ref{pStep} many times.
    \vb
  \item After the imputation model parameters have stabilized, save $M$ imputed 
    data sets produced in Step \ref{iStep}.
  \end{enumerate}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}
 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{iStep} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{pats}\hlstd{,} \hlkwc{ind}\hlstd{,} \hlkwc{p0}\hlstd{,} \hlkwc{pars}\hlstd{) \{}
    \hlcom{## Loop over non-trivial response patterns:}
    \hlkwa{for}\hlstd{(i} \hlkwa{in} \hlkwd{c}\hlstd{(}\hlnum{1} \hlopt{:} \hlkwd{nrow}\hlstd{(pats))[}\hlopt{-}\hlstd{p0]) \{}
        \hlcom{## Define the current response pattern:}
        \hlstd{p1} \hlkwb{<-} \hlstd{pats[i, ]}

        \hlcom{## Subset the data:}
        \hlstd{dat1} \hlkwb{<-} \hlstd{data[ind} \hlopt{==} \hlstd{i, ]}

        \hlcom{## Replace missing data with imputations:}
        \hlstd{data[ind} \hlopt{==} \hlstd{i,} \hlopt{!}\hlstd{p1]} \hlkwb{<-} \hlkwd{getImps}\hlstd{(}\hlkwc{data}  \hlstd{= dat1,}
                                       \hlkwc{mu}    \hlstd{= pars}\hlopt{$}\hlstd{mu,}
                                       \hlkwc{sigma} \hlstd{= pars}\hlopt{$}\hlstd{sigma,}
                                       \hlkwc{p1}    \hlstd{= p1)}
    \hlstd{\}}

    \hlcom{## Return the imputed data:}
    \hlstd{data}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{getImps} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{mu}\hlstd{,} \hlkwc{sigma}\hlstd{,} \hlkwc{p1}\hlstd{) \{}
    \hlcom{## Partition the parameter matrices:}
    \hlstd{mY}  \hlkwb{<-} \hlkwd{matrix}\hlstd{(mu[}\hlopt{!}\hlstd{p1])}
    \hlstd{mX}  \hlkwb{<-} \hlkwd{matrix}\hlstd{(mu[p1])}
    \hlstd{sY}  \hlkwb{<-} \hlstd{sigma[}\hlopt{!}\hlstd{p1,} \hlopt{!}\hlstd{p1]}
    \hlstd{sX}  \hlkwb{<-} \hlstd{sigma[p1, p1]}
    \hlstd{cXY} \hlkwb{<-} \hlstd{sigma[p1,} \hlopt{!}\hlstd{p1]}

    \hlcom{## Compute the imputation model parameters:}
    \hlstd{beta}  \hlkwb{<-} \hlkwd{solve}\hlstd{(sX)} \hlopt{%*%} \hlstd{cXY}
    \hlstd{alpha} \hlkwb{<-} \hlstd{mY} \hlopt{-} \hlkwd{t}\hlstd{(beta)} \hlopt{%*%} \hlstd{mX}
    \hlstd{sE}    \hlkwb{<-} \hlstd{sY} \hlopt{-} \hlkwd{t}\hlstd{(beta)} \hlopt{%*%} \hlstd{sX} \hlopt{%*%} \hlstd{beta}

    \hlcom{## Pull out predictors:}
    \hlstd{X} \hlkwb{<-} \hlkwd{as.matrix}\hlstd{(data[ , p1])}

    \hlcom{## Generate and return the imputations:}
    \hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(X)}
    \hlkwd{matrix}\hlstd{(}\hlnum{1}\hlstd{, n)} \hlopt{%*%} \hlkwd{t}\hlstd{(alpha)} \hlopt{+} \hlstd{X} \hlopt{%*%} \hlstd{beta} \hlopt{+} \hlkwd{rmvnorm}\hlstd{(n,} \hlkwc{sigma} \hlstd{= sE)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pStep} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{) \{}
    \hlcom{## Update the complete-data sufficient statistics:}
    \hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(data)}
    \hlstd{m} \hlkwb{<-} \hlkwd{colMeans}\hlstd{(data)}
    \hlstd{s} \hlkwb{<-} \hlstd{(n} \hlopt{-} \hlnum{1}\hlstd{)} \hlopt{*} \hlkwd{cov}\hlstd{(data)}

    \hlcom{## Sample sigma and mu:}
    \hlstd{sigma} \hlkwb{<-} \hlkwd{riwish}\hlstd{((n} \hlopt{-} \hlnum{1}\hlstd{), s)}
    \hlstd{mu}    \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlnum{1}\hlstd{, m, (sigma} \hlopt{/} \hlstd{n))}

    \hlcom{## Return the updated parameters:}
    \hlkwd{list}\hlstd{(}\hlkwc{mu} \hlstd{= mu,} \hlkwc{sigma} \hlstd{= sigma)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

  Now that we've defined the necessary functions, do the imputation:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Some preliminaries:}
\hlstd{impData} \hlkwb{<-} \hlstd{missData}
\hlstd{nIter}   \hlkwb{<-} \hlnum{50}
\hlstd{nImps}   \hlkwb{<-} \hlnum{100}

\hlcom{## Summarize response patterns:}
\hlstd{rMat} \hlkwb{<-} \hlopt{!}\hlkwd{is.na}\hlstd{(impData)}
\hlstd{pats} \hlkwb{<-} \hlkwd{uniquecombs}\hlstd{(rMat)}
\hlstd{ind}  \hlkwb{<-} \hlkwd{attr}\hlstd{(pats,} \hlstr{"index"}\hlstd{)}
\hlstd{p0}   \hlkwb{<-} \hlkwd{which}\hlstd{(}\hlkwd{apply}\hlstd{(pats,} \hlnum{1}\hlstd{, all))}

\hlcom{## Get starting values for the parameters:}
\hlstd{pars} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{mu}    \hlstd{=} \hlkwd{colMeans}\hlstd{(impData,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{),}
             \hlkwc{sigma} \hlstd{=} \hlkwd{cov}\hlstd{(impData,} \hlkwc{use} \hlstd{=} \hlstr{"pairwise"}\hlstd{)}
             \hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Iterate over I- and P-Steps to generate imputations:}
\hlstd{impList3} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(m} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nImps) \{}
    \hlkwa{for}\hlstd{(rp} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nIter) \{}
        \hlstd{impData} \hlkwb{<-} \hlkwd{iStep}\hlstd{(}\hlkwc{data} \hlstd{= impData,}
                         \hlkwc{pats} \hlstd{= pats,}
                         \hlkwc{ind}  \hlstd{= ind,}
                         \hlkwc{p0}   \hlstd{= p0,}
                         \hlkwc{pars} \hlstd{= pars)}
        \hlstd{pars} \hlkwb{<-} \hlkwd{pStep}\hlstd{(impData)}

        \hlkwa{if}\hlstd{(rp} \hlopt{==} \hlstd{nIter) impList3[[m]]} \hlkwb{<-} \hlstd{impData}
    \hlstd{\}}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}
  
  Do the same type of imputation with \texttt{norm}:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{missData} \hlkwb{<-} \hlkwd{as.matrix}\hlstd{(missData)}

\hlstd{meta}   \hlkwb{<-} \hlkwd{prelim.norm}\hlstd{(missData)}
\hlstd{theta0} \hlkwb{<-} \hlkwd{em.norm}\hlstd{(meta,} \hlkwc{showits} \hlstd{=} \hlnum{FALSE}\hlstd{)}

\hlkwd{rngseed}\hlstd{(}\hlnum{235711}\hlstd{)}

\hlstd{impList4} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(m} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nImps) \{}
    \hlstd{theta1} \hlkwb{<-} \hlkwd{da.norm}\hlstd{(}\hlkwc{s}     \hlstd{= meta,}
                      \hlkwc{start} \hlstd{= theta0,}
                      \hlkwc{steps} \hlstd{= nIter)}
    \hlstd{impList4[[m]]} \hlkwb{<-} \hlkwd{imp.norm}\hlstd{(}\hlkwc{s}     \hlstd{= meta,}
                              \hlkwc{theta} \hlstd{= theta1,}
                              \hlkwc{x}     \hlstd{= missData)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

  Analyze the multiply imputed data:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Manual implementation:}
\hlstd{fits3} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList3,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,} \hlkwc{data} \hlstd{= x)}
                \hlstd{)}
\hlstd{pool3} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits3)}

\hlcom{## Imputation using norm():}
\hlstd{fits4} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList4,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,}
                               \hlkwc{data} \hlstd{=} \hlkwd{as.data.frame}\hlstd{(x)}
                               \hlstd{)}
                \hlstd{)}
\hlstd{pool4} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits4)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Example: Joint Modeling}

  Compare approaches:\\
  \vb
  
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Fri Oct 19 00:20:17 2018
\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{rlllll}
  \toprule
 & Est & SE & t & p & FMI \\ 
  \midrule
(Intercept) & 0.023 & 0.043 & 0.529 & 0.597 & 0.545 \\ 
  x2 & 0.169 & 0.045 & 3.729 & $<$0.001 & 0.597 \\ 
  x3 & 0.212 & 0.05 & 4.228 & $<$0.001 & 0.651 \\ 
   \bottomrule
\end{tabular}
}
\caption{Manual Version} 
\end{table}
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Fri Oct 19 00:20:17 2018
\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{rlllll}
  \toprule
 & Est & SE & t & p & FMI \\ 
  \midrule
(Intercept) & 0.019 & 0.047 & 0.398 & 0.691 & 0.611 \\ 
  x2 & 0.164 & 0.044 & 3.755 & $<$0.001 & 0.569 \\ 
  x3 & 0.215 & 0.05 & 4.28 & $<$0.001 & 0.656 \\ 
   \bottomrule
\end{tabular}
}
\caption{NORM Version} 
\end{table}


\end{frame}

%------------------------------------------------------------------------------%

\end{document}
