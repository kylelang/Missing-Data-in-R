%%% Title:    Missing Data Stats Camp Course: MI Diagnostics
%%% Author:   Kyle M. Lang
%%% Created:  2017-SEP-12
%%% Modified: 2018-OCT-18

\documentclass{beamer}
\usetheme[%
  pageofpages          = of,
  bullet               = circle,
  titleline            = true,
  alternativetitlepage = true,
  titlepagelogo        = Logo3,
  watermark            = watermarkTiU,
  watermarkheight      = 100px,
  watermarkheightmult  = 4%
]{UVT}

\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{caption}
\usepackage{upgreek}

\newcommand{\bup}{\boldsymbol{\betaup}}

%% Ensure styles of `blocks' (used in Definitions, Theorems etc.) follows the
%% UVT-style theme:
\setbeamercolor{block title}{fg = darkblue, bg = white}
\setbeamercolor{block body}{use = block title, bg = block title.bg}

%% Ensure TableOfContents is in UVT-style theme:
\setbeamercolor{section in toc}{fg = darkblue}

%% Don't number broken frames
\setbeamertemplate{frametitle continuation}{}

%% Don't label table captions:
\captionsetup{labelformat = empty}

\title{Multiple Imputation with Categorical Variables}
\subtitle{Stats Camp 2018: Missing Data Analysis}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Tilburg University}
\date{19--21 October 2018}


\begin{document}

%------------------------------------------------------------------------------%

<<setup, include=FALSE>>=
set.seed(235711)

library(knitr)
library(ggplot2)
library(MASS)
library(mvtnorm)
library(glmnet)
library(xtable)
library(pscl)
library(LaplacesDemon)
library(MLmetrics)
library(SURF)
library(mice)
library(mitools)
library(norm)
library(MCMCpack)
library(mgcv)

source("../../../code/supportFunctions.R")
dataDir <- "../../../data/"
figDir  <- "figures/"

opts_chunk$set(size = 'footnotesize', fig.align = 'center')
knit_theme$set('edit-kwrite')

lightBlue <- rgb(0,   137, 191, max = 255)
midBlue   <- rgb(0,   131, 183, max = 255)
darkBlue  <- rgb(0,   128, 179, max = 255)
deepGold  <- rgb(184, 138, 45,  max = 255)
lightGold <- rgb(195, 146, 48,  max = 255)
@

%------------------------------------------------------------------------------%

\begin{frame}[t,plain]
  
  \titlepage
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  
  \begin{itemize}
  \item Discuss imputation diagnostics
    \vb
    \begin{itemize}
    \item Assessing imputation model convergence
      \vc
    \item Checking the imputations' plausibility
    \end{itemize}
    \vb
  \item Look at graphical and numerical options for both
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Example Data}
  
  These data were analyzed by \citet{langEtAl:2009}.\\
  \begin{itemize}
  \item $N = 87$
  \item $V = 33$
  \item Variables assessing: 
    \begin{itemize}
    \item Perceptions of and Definitions of Racism
    \item Political Affiliation
    \item Support for Affirmative Action Policies
    \item Belief in meritocratic ideals
    \end{itemize}
    \vb
  \item Almost no missing data
    \begin{itemize}
    \item I've artificially imposed $30\%$ MAR missing data on all variables 
      (expect political affiliation) using political affiliation as the MAR 
      predictor.
    \end{itemize}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%
      
\begin{frame}{Imputation Diagnostics}

  After we run an MI routine, we need to make sure that the procedure has 
  performed as expected.\\
  \va
  Problems can arise to two different places:
  \begin{enumerate}
    \item The imputation model may fail to converge.
    \item The imputed values may not be plausible.
  \end{enumerate}
  \va 
  We need to examine our results to check for these problems.
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Imputation Model Convergence}
  
  The imputation model is usually estimated through some form of Bayesian 
  simulation.
  \vb
  \begin{itemize}
  \item Gibbs sampled parameters form a \emph{Markov Chain}.
    \begin{itemize}
    \item Each draw is dependent on only its immediate predecessor in the chain.
    \item $\theta^{(t)} | \theta^{(t - 1)} \perp \theta^{(t - j)} ~ \forall j > 1$
    \end{itemize}
    \vb
  \item Early elements of a Markov chain are similar to the starting values.
    \begin{itemize}
    \item Samples are poor approximations of the true posterior.
    \end{itemize}
    \vb
  \item We must let the sampler iterate for a while to allow the estimates time 
    to separate from their starting values.
    \begin{itemize}
    \item We call these initial iterations ``burn-in'' or ``warm-up'' 
      iterations.
    \end{itemize}
  \end{itemize}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Traceplots}
  
  Once converged, each sampled imputation model parameter should ``bounce'' 
  around an equilibrium point.
  \begin{itemize}
  \item The draws will never converge onto a single point.
  \item That would defeat the purpose of simulation-based inference.
  \end{itemize}
  
  \begin{columns}
    \begin{column}{0.5\textwidth}
      
<<echo = FALSE, warning = FALSE, out.width = "95%">>=
missData  <- readRDS(paste0(dataDir, "adamsKlpsMissData.rds"))
nSams     <- 1000
missData  <- as.matrix(missData)
thetaHat1 <- list()

## Do preliminary manipulations:
metaData       <- prelim.norm(missData) 

## Find the MLE:
thetaHat1[[1]] <- 100 * em.norm(metaData, showits = FALSE)

## Set random number generator seed:
rngseed(235711)   

for(s in 2 : nSams) {
    thetaHat1[[s]] <- da.norm(s     = metaData,
                              start = thetaHat1[[s - 1]],
                              steps = 1)
}

muIterMat1 <- matrix(
    unlist(
        lapply(thetaHat1,
               FUN = function(x, metaData) {
                   getparam.norm(s = metaData, theta = x)$mu
               },
               metaData = metaData)
    ),
    ncol  = ncol(missData),
    byrow = TRUE)

colnames(muIterMat1) <- colnames(missData)

plot(muIterMat1[ , "RIAE5"],
     type = "l",
     main = "Trace of RIAE5's Estimated Mean",
     xlab = "Iteration",
     ylab = "Mean of RIAE5")
@ 

\end{column}

\begin{column}{0.5\textwidth}
  
<<echo = FALSE, out.width = "95%">>=
plot(muIterMat1[ , "NORI4"],
     type = "l",
     main = "Trace of NORI4's Estimated Mean",
     xlab = "Iteration",
     ylab = "Mean of NORI4")
@ 

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Potential Scale Reduction Factor}
  
  Suppose we have two Markov chains for the same parameter.
  \vc 
  \begin{itemize}
  \item If these chains have converged, the average distance between any two
    points on separate chains should be the same as the average distance 
    between two points on the same chain.
    \vc
  \item The \emph{between-chain} variance should, on average, equal the 
    \emph{within-chain} variance.
  \end{itemize}
  \vc
  The \emph{Potential Scale Reduction Factor} $\widehat{R}$ quantifies this 
  concept:
  \begin{align*}
    \widehat{R} = \frac{\hat{\sigma}^2_{between}}{\hat{\sigma}^2_{within}}
  \end{align*}
  $\widehat{R}$ will approach 1.0 at convergence.
  \vc
  \begin{itemize}
  \item $\widehat{R} < $ 1.1 or 1.2 suggests acceptable convergence.
  \end{itemize}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Example: Potential Scale Reduction Factor}
   
<<echo = FALSE, out.width = "65%">>=
thetaHat2 <- list()

thetaHat2[[1]] <- -100 * em.norm(metaData, showits = FALSE)
rngseed(117532) # Set random number generator seed

for(s in 2 : nSams) {
    thetaHat2[[s]] <- da.norm(s = metaData,
                              start = thetaHat2[[s - 1]],
                              steps = 1)
}

muIterMat2 <- matrix(
    unlist(
        lapply(thetaHat2,
               FUN = function(x, metaData) {
                   getparam.norm(s = metaData, theta = x)$mu
               },
               metaData = metaData)
    ),
    ncol  = ncol(missData),
    byrow = TRUE)

colnames(muIterMat2) <- colnames(missData)

chain1 <- muIterMat1[ , "RIAE5"]
chain2 <- muIterMat2[ , "RIAE5"]

yRange <- range(chain1, chain2)

plot(chain1,
     type = "l",
     ylim = yRange,
     col  = "red",
     main = "Multi-Chain Trace of RIAE5's Estimated Mean",
     xlab = "Iteration",
     ylab = "Mean of RIAE5")
lines(chain2, col = "blue")
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Potential Scale Reduction Factor}
  
<<size = "scriptsize">>=
## Create matrices of the full and burnt-in chains:
iterMat  <- cbind(chain1, chain2)
burntMat <- iterMat[201 : 1000, ]

## Full Chain R-Hat:
wVar1 <- mean(apply(iterMat, 2, var))
bVar1 <- mean(apply(iterMat, 1, var))
rHat1 <- bVar1 / wVar1
rHat1

## Burnt-In R-Hat:
wVar2 <- mean(apply(burntMat, 2, var))
bVar2 <- mean(apply(burntMat, 1, var))
rHat2 <- bVar2 / wVar2
rHat2
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{More Imputation Model Convergence}
  
  A convergent imputation model will produce imputed values that
  fluctuate around an equilibrium point. 
  \vb
  \begin{itemize}
  \item Imputation model convergence can be assessed indirectly by
    looking at plots of the item-level sufficient statistics for each
    imputation.
  \end{itemize}
  \va
  This approach is automated for \textbf{mice} via \texttt{plot.mice()}.
  \va

<<out.width = "65%">>=
miceOut1 <- readRDS(paste0(dataDir, "miceOut1.rds"))
plot(miceOut1, c("RIAE5", "NORI4", "POLICY2"))
@ 

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Imputed Value Plausibility}
  
  We need to ensure that the imputations are sensible.
  \vc
  \begin{itemize}
  \item Imputed values shouldn't be \emph{too} dissimilar from their observed 
    counterparts.
    \begin{itemize}
    \item What constitutes \emph{too} much dissimilarity is subjective and 
      problem-specific.
    \end{itemize}
  \end{itemize}
  \vb
  We can assess dissimilarity graphically or through summary statistics.
  \vc
  \begin{itemize}
  \item Out-of-bounds values for the imputations are perfectly acceptable.
    \begin{itemize}
    \item MI is \emph{NOT} designed to maintain the range.
    \item We don't want wildly extreme values, though.
    \end{itemize}
    \vc
  \item The means of the observed and imputed components of each variable 
    shouldn't differ too much.
    \begin{itemize}
    \item Again, how much is \emph{too} much is subjective.
    \end{itemize}
  \end{itemize}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Numeric Imputation Checks}
  
<<echo = FALSE>>=
impList <- list()
for(m in 1 : miceOut1$m)
    impList[[m]] <- complete(miceOut1, m)
@ 

<<>>=
rawMeans <- colMeans(missData, na.rm = TRUE)
impMeans <- colMeans(do.call("rbind", impList))

rawSds <- apply(missData, 2, sd, na.rm = TRUE)
sdList <- lapply(impList, function(x) sapply(x, FUN = sd))
impSds <- colMeans(do.call(rbind, sdList))

rawRanges <- apply(missData, 2, range, na.rm = TRUE)
impRanges <- sapply(do.call("rbind", impList), range)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Numeric Imputation Checks}

<<>>=
round(rawMeans[1 : 5], 3)
round(impMeans[1 : 5], 3)
@ 

\pagebreak

<<>>=
round(rawSds[1 : 5], 3)
round(impSds[1 : 5], 3)
@

\pagebreak

<<>>=
round(rawRanges[ , 1 : 5], 3)
round(impRanges[ , 1 : 5], 3)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Graphical Imputation Checks}

<<size = "scriptsize", out.width = "65%", out.height = "65%">>=
## Overlaid density plots of imputed vs. observed values:
densityplot(miceOut1, data = ~RIAE5 + NORI4 + WPRIV7, 
            layout = c(3, 1))
@ 
     
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Graphical Imputation Checks}

<<size = "scriptsize", out.width = "65%", out.height = "65%">>=
## Scatterplots of imputed vs. observed values:
stripplot(miceOut1, data = RIAE5 + NORI4 + WPRIV7 ~ .imp, 
          layout = c(3, 1))
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Graphical Imputation Checks}
    
  We can use the \texttt{plotImps} function from the \textbf{SURF} package to 
  generate overlaid density plots for arbitrary lists of imputed data.
  
<<out.width = "65%">>=
## Overlaid density plots of imputed vs. observed values:
par(mfrow = c(1, 3), cex.main = 0.9)

rMat                 <- is.na(miceOut1$data)
type                 <- miceOut1$method
type[type == "norm"] <- "con"

plotImps(impList   = impList, 
         rMat      = rMat, 
         typeVec   = type, 
         targetVar = c("RIAE5", "NORI4", "WPRIV7"))
@ 

\end{frame}

\watermarkon %----------------------------------------------------------------%

\begin{frame}{References}

  \bibliographystyle{apacite}
  \bibliography{../../../literature/bibtexFiles/appliedRefs.bib}

\end{frame}

%------------------------------------------------------------------------------%

\end{document}
