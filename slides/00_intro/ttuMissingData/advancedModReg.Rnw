\documentclass{beamer}
\usetheme{TTU}
\usefonttheme{serif}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathptmx}
\usepackage{url}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{esint}
\usepackage[natbibapa]{apacite}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{Sweavel}
\usepackage{listings}

\def\Sweavesize{\scriptsize}
\def\Rcolor{\color{black}}
%\def\Routcolor{\color{red}}
\def\Rcommentcolor{\color{violet}}
\def\Rbackground{\color[gray]{0.85}}
\def\Routbackground{\color[gray]{0.85}}

\lstset{tabsize=2, breaklines=true, style=Rstyle}

\SweaveOpts{keep.source=T, prefix.string=sweaveFiles/immapTalk, split=T, ae=F, height=4, width=6}

\newcommand{\red}[0]{\textcolor{red}}
%\newcommand{\violet}[0]{\textcolor{violet}}
\newcommand{\green}[0]{\textcolor{green}}
\newcommand{\blue}[0]{\textcolor{blue}}
\newcommand{\comment}[1]{}
\newcommand{\kfold}[0]{\emph{K}-fold cross-validation}

\title[Advanced Regularized Regression]{Advanced Applications of Regularized Regression Modeling for SEM and Affiliated Problems}

\author{Kyle M. Lang}

\institute[TTU IMMAP]{
  Institute for Measurement, Methodology, Analysis and Policy\\
  Texas Tech University\\
  Lubbock, TX
}

\date{June 12, 2015}


\begin{document}

\setkeys{Gin}{width=\textwidth}
  
<<echo=F>>=
options(width=160, prompt=" ", continue=" ", useFancyQuotes = TRUE)
source("code/modRegFunctions.R")
library(xtable)
library(mvtnorm)
library(mice)
@ 


% Use a custom background template for the title slide
{\usebackgroundtemplate{\rule{0pt}{3.4in}\hspace*{2.25in}
    \makebox[0pt][r]{\includegraphics[natwidth=1000bp, natwidth=283bp,width=2in]{TTU_Logo.png}}}
  
  \begin{frame}[plain]
    
    \titlepage
    
  \end{frame}
}% CLOSE Custom Background Template



\begin{frame}{Outline}
  
  \begin{itemize}
  \item More on missing data mechanisms
  \item A few more missing data diagnostics
  \item Ad Hoc techniques and their problems
  \item More on MI and FIML
  \end{itemize}
  
\end{frame}


\begin{frame}{Missing Data Mechanisms}

  MCAR:
  \begin{align}
    P(R | Y_{mis}, Y_{obs}) = P(R)
  \end{align}
  MAR:
  \begin{align}
    P(R | Y_{mis}, Y_{obs}) = P(R | Y_{obs})
  \end{align}
  MNAR:
  \begin{align}
    P(R | Y_{mis}, Y_{obs}) \neq P(R | Y_{obs})
  \end{align}
  
\end{frame}

\begin{frame}{Simulate Some Toy Data}
  
<<>>=

nObs <- 1000
pm <- 0.3

sigma <- matrix(c(1.0, 0.5, 0.0,
                  0.5, 1.0, 0.3,
                  0.0, 0.3, 1.0),
                ncol = 3)
simDat <- as.data.frame(rmvnorm(nObs, c(0, 0, 0), sigma))
colnames(simDat) <- c("y", "x", "z")

x <- simDat$x
y <- simDat$y
z <- simDat$z

cor(y, x)
@ 

\end{frame}


\begin{frame}{MCAR Example}
  
<<>>=

## MCAR:
rVec1 <- as.logical(rbinom(nObs, size = 1, prob = pm))
mean(rVec1)

y2 <- y
y2[rVec1] <- NA

cor(y2, x, use = "pairwise")

@ 

<<fig=T, echo=F>>=

yDen <- density(y)
y2Den <- density(y2, na.rm = TRUE)

yLim <- range(c(yDen$y, y2Den$y))
xLim <- range(c(yDen$x, y2Den$x))

plot(yDen, ylim = yLim, xlim = xLim)
lines(y2Den, col = "red")
legend(x = "topright",
       legend = c("Complete", "MCAR"),
       col = c("black", "red"),
       lty = 1,
       lwd = 1)

@ 

\end{frame}

\end{document}






data(diabetes)

nChains <- 2
nDraws <- 10000
nBurn <- 5000

### Run Bayesian Ridge Regression:
bRidgeOut <- list()
for(i in 1 : nChains) {
  bRidgeOut[[i]] <- bridge(X = diabetes$x2,
                           y = diabetes$y,
                           T = 10000,
                           thin = 1,
                           RJ = FALSE,
                           M = ncol(diabetes$x2),
                           rao.s2 = FALSE,
                           verb = 0)
}
@ 

\end{frame}



\begin{frame}{Fit Bayesian LASSO}
<<>>=
nChains <- 2
nDraws <- 10000
nBurn <- 5000

### Run Bayesian LASSO:
bLassoOut <- list()
for(i in 1 : nChains) {
  bLassoOut[[i]] <- blasso(X = diabetes$x2,
                           y = diabetes$y,
                           T = 10000,
                           thin = 1,
                           RJ = FALSE,
                           M = ncol(diabetes$x2),
                           rao.s2 = FALSE,
                           verb = 0)
}
@
  
\end{frame}




\begin{frame}{MCMC Trace Plots for LASSO \& Ridge $\sigma^2$s, \& $\lambda$s}
  
<<fig=T, echo=F>>=

par(mfrow = c(2, 2),
    family = "serif",
    mar = c(2, 3, 2, 1),
    cex = 0.75)

## LASSO Lambda
plot(bLassoOut[[1]]$lambda,
     col = "red",
     type = "l",
     main = "LASSO Lambda",
     ylab = "Lambda")
lines(bLassoOut[[2]]$lambda, col = "blue")

## Ridge Lambda
plot(bRidgeOut[[1]]$lambda,
     col = "red",
     type = "l",
     main = "Ridge Lambda",
     ylab = "Lambda")
lines(bRidgeOut[[2]]$lambda, col = "blue")

## Lasso Sigma2
plot(bLassoOut[[1]]$s2,
     col = "red",
     type = "l",
     main = "LASSO Sigma2",
     ylab = "Sigma2")
lines(bLassoOut[[2]]$s2, col = "blue")

## Ridge Sigma2
plot(bRidgeOut[[1]]$s2,
     col = "red",
     type = "l",
     main = "Ridge Sigma2",
     ylab = "Sigma2")
lines(bRidgeOut[[2]]$s2, col = "blue")
@ 

\end{frame}





\begin{frame}{MCMC Trace Plots for Ridge $\beta$s}

<<fig=T, echo=F>>=
## Ridge Betas:
par(mfrow = c(4, 4),
    family = "serif",
    mar = c(2, 4, 1, 1),
    cex.axis = 0.6)

for(i in 1 : 16) {
  plot(bRidgeOut[[1]]$beta[ , i],
       col = "red",
       type = "l",
       ylab = colnames(diabetes$x2)[i])
  lines(bRidgeOut[[2]]$beta[ , i], col = "blue")
}
@

\end{frame}





\begin{frame}{MCMC Trace Plots for LASSO $\beta$s}

<<fig=T, echo=F>>=
## LASSO Betas:
par(mfrow = c(4, 4),
    family = "serif",
    mar = c(2, 4, 1, 1),
    cex.axis = 0.6)

for(i in 1 : 16) {
  plot(bLassoOut[[1]]$beta[ , i],
       col = "red",
       type = "l",
       ylab = colnames(diabetes$x2)[i])
  lines(bLassoOut[[2]]$beta[ , i], col = "blue")
}
@ 

\end{frame}





\begin{frame}{Posterior Density Plots of $\lambda$ \& $\sigma^2$}
  
<<echo=F>>=
### Pool the MC iterates into final posterior samples:
lambdaPostL <- c(bLassoOut[[1]]$lambda[(nBurn + 1) : nDraws],
                 bLassoOut[[2]]$lambda[(nBurn + 1) : nDraws])

sigma2PostL <- c(bLassoOut[[1]]$s2[(nBurn + 1) : nDraws],
                 bLassoOut[[2]]$s2[(nBurn + 1) : nDraws])

betaPostL <- rbind(bLassoOut[[1]]$beta[(nBurn + 1) : nDraws, ],
                   bLassoOut[[2]]$beta[(nBurn + 1) : nDraws, ])

lambdaPostR <- c(bRidgeOut[[1]]$lambda[(nBurn + 1) : nDraws],
                 bRidgeOut[[2]]$lambda[(nBurn + 1) : nDraws])

sigma2PostR <- c(bRidgeOut[[1]]$s2[(nBurn + 1) : nDraws],
                 bRidgeOut[[2]]$s2[(nBurn + 1) : nDraws])

betaPostR <- rbind(bRidgeOut[[1]]$beta[(nBurn + 1) : nDraws, ],
                   bRidgeOut[[2]]$beta[(nBurn + 1) : nDraws, ])
@

<<echo=F, fig=T>>=
par(mfrow = c(1, 2),
    family = "serif")
### Plot posterior densities of lambda:
lassoDat <- density(lambdaPostL)
ridgeDat <- density(lambdaPostR)

yBounds <- c(min(min(lassoDat$y, ridgeDat$y)),
             max(max(lassoDat$y, ridgeDat$y)))
xBounds <- c(min(min(lassoDat$x, ridgeDat$x)),
             max(max(lassoDat$x, ridgeDat$x)))

plot(density(lambdaPostL),
     ylim = yBounds,
     xlim = xBounds,
     col = "blue",
     main = "Lambda",
     xlab = "")
lines(density(lambdaPostR), col = "red")


### Plot posterior densities of sigma2:
lassoDat <- density(sigma2PostL)
ridgeDat <- density(sigma2PostR)

yBounds <- c(min(min(lassoDat$y, ridgeDat$y)),
             max(max(lassoDat$y, ridgeDat$y)))
xBounds <- c(min(min(lassoDat$x, ridgeDat$x)),
             max(max(lassoDat$x, ridgeDat$x)))
      
plot(density(sigma2PostL),
     ylim = yBounds,
     xlim = xBounds,
     col = "blue",
     main = "Sigma2",
     xlab = "")
lines(density(sigma2PostR), col = "red")
@ 

\textsc{Legend:} \red{Ridge}, \blue{LASSO}
\end{frame}





\begin{frame}{Posterior Density Plots of $\beta$s}
 
<<echo=F, fig=T>>=
### Plot posterior densities of beta:
par(mfrow = c(4, 4),
    family = "serif",
    mar = c(4, 2, 1, 2),
    cex.axis = 0.6)

for(i in 1 : 16) {
  lassoDat <- density(betaPostL[ , i])
  ridgeDat <- density(betaPostR[ , i])

  yBounds <- c(min(min(lassoDat$y, ridgeDat$y)),
               max(max(lassoDat$y, ridgeDat$y)))
  xBounds <- c(min(min(lassoDat$x, ridgeDat$x)),
               max(max(lassoDat$x, ridgeDat$x)))
               
  ridgeDat
  plot(density(betaPostL[ , i]),
       ylim = yBounds,
       xlim = xBounds,
       col = "blue",
       main = "",
       xlab = colnames(diabetes$x2)[i],
       yaxt = "n")
  lines(density(betaPostR[ , i]), col = "red")
}
@ 

\end{frame}




\begin{frame}[allowframebreaks]{Credible Intervals for LASSO $\beta$s}
  
<<echo=F, results=tex>>=
### Calculate credible intervals for beta:
lassoBetaCI <- apply(betaPostL, 2, quantile, probs = c(0.025, 0.975))
ridgeBetaCI <- apply(betaPostR, 2, quantile, probs = c(0.025, 0.975))

colnames(lassoBetaCI) <- colnames(ridgeBetaCI) <- colnames(diabetes$x2)

lassoCiMat <- round(lassoBetaCI, 1)
ridgeCiMat <- round(ridgeBetaCI, 1)

ciTab1 <- xtable(lassoCiMat[ , 1 : 8], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )

ciTab2 <- xtable(lassoCiMat[ , 9 : 16], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab3 <- xtable(lassoCiMat[ , 17 : 24], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab4 <- xtable(lassoCiMat[ , 25 : 32], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab5 <- xtable(lassoCiMat[ , 33 : 40], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab6 <- xtable(lassoCiMat[ , 41 : 48], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab7 <- xtable(lassoCiMat[ , 49 : 56], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )


ciTab8 <- xtable(lassoCiMat[ , 57 : 64], 
                 #caption = "LASSO Credible Intervals",
                 digits = 1,
                 align = c( "|r|",rep( "c|", 8 ) )
                 )

print(ciTab1, scalebox = .7)
print(ciTab2, scalebox = .7)
print(ciTab3, scalebox = .7)
print(ciTab4, scalebox = .7)
print(ciTab5, scalebox = .7)
print(ciTab6, scalebox = .7)
print(ciTab7, scalebox = .7)
print(ciTab8, scalebox = .7)
@ 

\end{frame}






\begin{frame}[allowframebreaks]{Credible Intervals for Ridge $\beta$s}
  
<<echo=F, results=tex>>=
ciTabR1 <- xtable(ridgeCiMat[ , 1 : 8], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )

ciTabR2 <- xtable(ridgeCiMat[ , 9 : 16], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR3 <- xtable(ridgeCiMat[ , 17 : 24], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR4 <- xtable(ridgeCiMat[ , 25 : 32], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR5 <- xtable(ridgeCiMat[ , 33 : 40], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR6 <- xtable(ridgeCiMat[ , 41 : 48], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR7 <- xtable(ridgeCiMat[ , 49 : 56], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


ciTabR8 <- xtable(ridgeCiMat[ , 57 : 64], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                 )

print(ciTabR1, scalebox = .7)
print(ciTabR2, scalebox = .7)
print(ciTabR3, scalebox = .7)
print(ciTabR4, scalebox = .7)
print(ciTabR5, scalebox = .7)
print(ciTabR6, scalebox = .7)
print(ciTabR7, scalebox = .7)
print(ciTabR8, scalebox = .7)
@ 

\end{frame}





\begin{frame}[allowframebreaks]{MAP Scores for $\beta$s}
  
<<echo=F, results=tex>>=
lassoBetaMAP <- colMedians(betaPostL)
ridgeBetaMAP <- colMedians(betaPostR)

betaMapMat <- round(rbind(lassoBetaMAP, ridgeBetaMAP), 2)

colnames(betaMapMat) <- colnames(diabetes$x2)
rownames(betaMapMat) <- c("LASSO", "Ridge")

mapTab1 <- xtable(betaMapMat[ , 1 : 8], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )

mapTab2 <- xtable(betaMapMat[ , 9 : 16], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab3 <- xtable(betaMapMat[ , 17 : 24], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab4 <- xtable(betaMapMat[ , 25 : 32], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab5 <- xtable(betaMapMat[ , 33 : 40], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab6 <- xtable(betaMapMat[ , 41 : 48], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab7 <- xtable(betaMapMat[ , 49 : 56], 
                  digits = 1,
                  align = c( "|r|",rep( "c|", 8 ) )
                  )


mapTab8 <- xtable(betaMapMat[ , 57 : 64], 
                   digits = 1,
                   align = c( "|r|",rep( "c|", 8 ) )
                   )

print(mapTab1, scalebox = .7)
print(mapTab2, scalebox = .7)
print(mapTab3, scalebox = .7)
print(mapTab4, scalebox = .7)
print(mapTab5, scalebox = .7)
print(mapTab6, scalebox = .7)
print(mapTab7, scalebox = .7)
print(mapTab8, scalebox = .7)
@ 

\end{frame}




\begin{frame}{Ridge for SEM}
  
  When the observed covariance matrix is computationally singular,
  applying a ridge constant can facilitate estimation of SEMs.
  \vspace{6pt}
  \begin{itemize}
    \item Lisrel and Lavaan offer the option to apply a ridge constant
      to the observed covariance matrix.
    \item Mplus will ridge observed covariates as needed, but does not
      allow user control.
    \item A ridge constant can easily be added to any covariance
      matrix manually.
  \end{itemize}
  \vspace{6pt}
  \pause 
  Let $\mathbf{S} = cov(X)$ be a covariance matrix of manifest
  variables, then $\mathbf{S}$ can be ``ridged'' by:
  \begin{align*}
    \mathbf{S}_{ridge} = \mathbf{S} + a \mathbf{I}_P
  \end{align*}

\end{frame}




\begin{frame}{Performance of Ridge for SEM}
  
  \citet{yuanChan:2008} and \citet*{yuanEtAl:2011} studied the behavior of ridge
  in the SEM context.
  \vspace{6pt}
  \begin{itemize}
    \item They showed that ridging $\mathbf{X}$ does not bias any
      model parameters except for the residual variances which are
      inflated by a constant value of $a$.
      \vspace{6pt}
    \item Model fit indices are untrustworthy in ridged SEM
      \vspace{6pt}
    \item Standard Errors may also be biased
      \vspace{3pt}
      \begin{itemize}
        \item The problems with SEs and fit indices can be mitigated with
          bootstrapping or robust statistics
      \end{itemize}
  \end{itemize}
  
\end{frame}




\begin{frame}[allowframebreaks]{Demonstration}
  
<<>>=
toyDat <- simSimpleData(500)

mod1 <- "
fac1 =~ x1 + x2 + x3
fac2 =~ x4 + x5 + x6
fac3 =~ x7 + x8 + x9
"

ridgeVal <- ncol(toyDat) / nrow(toyDat)

ridgeCov <- cov(toyDat) + ridgeVal * diag(ncol(toyDat))

out1 <- cfa(mod1, # Model the ridged covariance matix
            sample.cov = ridgeCov,
            sample.nobs = nrow(toyDat),
            std.lv = TRUE)

out2 <- cfa(mod1, # Model the raw covariance matrix
            sample.cov = cov(toyDat),
            sample.nobs = nrow(toyDat),
            std.lv = TRUE)

lam1 <- inspect(out1, "coef")$lambda
lam2 <- inspect(out2, "coef")$lambda
lam1 - lam2
@ 
No difference in the factor loadings
<<>>=
psi1 <- inspect(out1, "coef")$psi
psi2 <- inspect(out2, "coef")$psi
psi1 - psi2
@
No difference in the latent covariances
<<>>=
theta1 <- inspect(out1, "coef")$theta
theta2 <- inspect(out2, "coef")$theta
diag(theta1 - theta2)
@ 
There are differences in the residual variances, and they're equal to the ridge constant.
<<>>=
ridgeVal
@

\end{frame}




\begin{frame}[allowframebreaks]{Demonstration with Perfect Collinearity}
  
<<>>=
toyDat2 <- toyDat # perfectly collinear data
toyDat2[ , 1] <- toyDat2[ , 2] + toyDat2[ , 3]

ridgeVal <- 2.2

ridgeCov <- cov(toyDat2) + ridgeVal * diag(ncol(toyDat2))

out3 <- cfa(mod1, # Model the ridged covariance matix
            sample.cov = ridgeCov,
            sample.nobs = nrow(toyDat2),
            std.lv = TRUE)

summary(out3)
@

\end{frame}



\begin{frame}{Ridge for SEM: Concluding Thoughts}
  
  Ridging can make your SEM estimable, but it's probably not too useful in practice.
  \vspace{6pt}
  \begin{itemize}
    \item If your observed covariance matrix is singular, you're
      better off trying to adjust your model specification rather than
      applying a ridge correction.
      \vspace{6pt}
    \item Ridging may be more useful with categorical variables \citep{yuanEtAl:2011}.
      \vspace{6pt}
    \item If you do use ridged SEM, do not trust the naive fit indices and be careful of SEs.
      \vspace{3pt}
      \begin{itemize}
      \item Probably safest to use parametric boostrapping for inference
      \end{itemize}
  \end{itemize}
  
\end{frame}





\begin{frame}{LASSO for SEM}
  
  \citet*{guoEtAl:2012} developed a semi-parametric SEM technique that
  employed the Bayesian LASSO in combination with basis expansion to
  automatically detect important nonlinearities among the latent
  variables of an SEM.
  \begin{itemize}
    \item There method performed well in simulations, but there is no
      software available to implement it.
  \end{itemize}
  \pause
  \vspace{12pt}
  \citet{choi:2010}, \citet{hiroseKonishi:2012}, and
  \citet{hiroseYamamoto:2014} have all explored the use of a LASSO
  penalty for EFA as a way to address the rotational indeterminacy
  problem.
  \begin{itemize}
  \item The automatic variable selection of the LASSO can be used to
    extract an interpretable set of latent factors without the need
    for factor rotation.
  \end{itemize}
  
\end{frame}





\begin{frame}[shrink = 5]{Interesting Application: Regularization for MI}
  
  Regularized regression is central to MI
  \begin{itemize}
  \item Nearly all normal-theory imputation models are based on ridge regression
    \vspace{6pt}
    \pause
  \item Most MI software allows the user to control the value of the ridge penalty:
    \begin{itemize}
    \item SAS Proc MI: \texttt{prior = ridge =} $\lambda$
    \item Amelia II: \texttt{empri =} $\lambda$
    \item MICE: \texttt{ridge =} $\lambda$
    \end{itemize}
    \vspace{6pt}
    \pause
  \item \citet{zhaoLong:2013} developed a multiple imputation scheme based on the Bayesian LASSO
    \vspace{3pt}
    \begin{itemize}
    \item Their method performed very well when compared to: 
      \begin{itemize}
      \item Ordinary MICE (with a ridge prior)
      \item MI based on frequentist LASSO
      \item MI based on frequentist elastic net
      \end{itemize}
    \end{itemize}
    \vspace{6pt}
    \pause
  \item \citet{lang:2015} extended the work of \citet{zhaoLong:2013}
    by developing a novel MI method, \emph{Multiple Imputation with
      the Elastic Net}, that was based on the \citet{liLin:2010}
    Bayesian elastic net.
  \end{itemize}
  
\end{frame}
  
  


\begin{frame}[allowframebreaks]{References}

  \bibliographystyle{apacite}
  \bibliography{bibtexFiles/dissRefsList.bib,bibtexFiles/researchDesignRefs.bib,bibtexFiles/modelRegRefs.bib}
 
\end{frame}





\begin{frame}{Thank you for your time.}

  \begin{center}\textsc{\huge{Questions/Comments?}}\end{center}

\end{frame}


\end{document}
