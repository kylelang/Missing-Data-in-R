%%% Title:    Missing Data in R: Introduction
%%% Author:   Kyle M. Lang
%%% Created:  2015-11-06
%%% Modified: 2022-01-23

\documentclass{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{eurosym}
\usepackage{caption}

\captionsetup{labelformat = empty}

\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}


\title{Missing Data Basics}
\subtitle{Utrecht University Winter School: Missing Data in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{2022-02-03}

%------------------------------------------------------------------------------%

\begin{document}

<<setup, include = FALSE, cache = FALSE>>=
set.seed(235711)

library(knitr)
library(ggplot2)
library(mice)
library(mvtnorm)
library(xtable)
library(pROC)
library(dplyr)
library(magrittr)
library(naniar)
library(gridExtra)
library(ggpubr)
library(lme4)

source("../../../code/supportFunctions.R")
source("../../../code/sim_missing/code/simMissingness.R")

dataDir <- "../../../data/"

options(width = 60)
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/intro-",
               message = FALSE,
               warning = FALSE,
               comment = "")
knit_theme$set('edit-kwrite')
@

%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Introduction}

  \begin{enumerate}
  \item What's your name?
    \vc
  \item Where are you from/where do you work?
    \vc
  \item What type of research do you do?
    \vc
  \item What type of missing data problems do you encounter in your research?
    \vc
  \item What statistical software do you use/do you have programming experience?
    \vc
  \item What's your math background?
  \end{enumerate}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{What are Missing Data?}

  Missing data are empty cells in a dataset where there should be observed
  values.
  \vc
  \begin{itemize}
  \item The missing cells correspond to true population values, but we haven't
    observed those values.
  \end{itemize}
  \vb
  \pause
  Not every empty cell is a missing datum.
  \vc
  \begin{itemize}
  \item Quality-of-life ratings for dead patients in a mortality study
    \vc
  \item Firm profitability after the company goes out of business
    \vc
  \item Self-reported severity of menstrual cramping for men
    \vc
  \item Empty blocks of data following ``gateway'' items
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{A Little Notation}

  \begin{align*}
    Y &\coloneqq \text{An $N \times P$ Matrix of Arbitrary Data}\\[8pt]
    Y_{mis} &\coloneqq \text{The \emph{missing} part of $Y$}\\[8pt]
    Y_{obs} &\coloneqq \text{The \emph{observed} part of $Y$}\\[8pt]
    R &\coloneqq \text{An $N \times P$ response matrix}\\[8pt]
    M &\coloneqq \text{An $N \times P$ missingness matrix}
  \end{align*}

  The $R$ and $M$ matrices are complementary.
  \begin{itemize}
  \item $r_{np} = 1$ means $y_{np}$ is observed; $m_{np} = 1$ means $y_{np}$ is
    missing.
  \item $r_{np} = 0$ means $y_{np}$ is missing; $m_{np} = 0$ means $y_{np}$ is
    observed.
  \item $M_p$ is the \emph{missingness} of $Y_p$.
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Missing Data Descriptives}

%------------------------------------------------------------------------------%

\begin{frame}{Missing Data Pattern}

<<echo = FALSE>>=
tmpTab <- matrix(c("x", "x", ".", ".",
                   "y", ".", "y", "."),
                 ncol = 2,
                 dimnames = list(NULL, c("X", "Y"))
                 )

patTab1 <- xtable(tmpTab, align = rep("c", 3), caption = "Patterns for $P = 2$")

tmpTab <- matrix(c(rep("x", 3), ".", "x", rep(".", 3),
                   "y", "y", ".", "y", ".", ".", "y", ".",
                   "z", ".", "z", "z", ".", "z", ".", "."),
                 ncol = 3,
                 dimnames = list(NULL, c("X", "Y", "Z"))
                 )

patTab2 <- xtable(tmpTab, align = rep("c", 4), caption = "Patterns for $P = 3$")
@

Missing data (or response) patterns represent unique combinations of observed
and missing items.
\begin{itemize}
  \item $P$ items $\Rightarrow$ $2^P$ possible patterns.
\end{itemize}

\begin{columns}
  \begin{column}{0.45\textwidth}

<<echo = FALSE, results = 'asis'>>=
print(patTab1, booktabs = TRUE)
@

  \end{column}
  \begin{column}{0.45\textwidth}
\vx{-12}
<<echo = FALSE, results = 'asis'>>=
print(patTab2, booktabs = TRUE)
@

    \end{column}
  \end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Missing Data Pattern}

 The concept of a ``missing data pattern'' can also be used to classify the
  spatial arrangement of missing cells on a data set.\\

  \vc

  \begin{itemize}
  \item Univariate
    \begin{itemize}
      \item Missing data occur on only one variable
    \end{itemize}

    \vb

  \item Monotone
    \begin{itemize}
    \item The proportion of complete elements, in both rows and columns,
      decreases when traversing the data set.
    \item The observed cells can be arranged into a ``staircase'' pattern.
    \end{itemize}

    \vb

  \item Arbitrary
    \begin{itemize}
    \item Missing values are ``randomly'' scattered throughout the data set.
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Example Missing Data Patterns}

<<echo = FALSE>>=
tmpTab <- matrix(c(rep("x", 10),
                   rep("y", 5), rep(".", 5),
                   rep("z", 10)),
                 ncol = 3)
colnames(tmpTab) <- c("X", "Y", "Z")

patTab1 <- xtable(tmpTab,
                  align   = rep("c", 4),
                  caption = "Univariate Pattern")

tmpTab2 <- matrix(c(rep("x", 9), rep(".", 1),
                    rep("y", 6), rep(".", 4),
                    rep("z", 3), rep(".", 7)),
                  ncol = 3)
colnames(tmpTab2) <- c("X", "Y", "Z")

patTab2 <- xtable(tmpTab2,
                  align   = rep("c", 4),
                  caption = "Monotone Pattern")

tmpTab3 <- matrix(c(rep("x", 10),
                    rep("y", 10),
                    rep("z", 10)),
                  ncol = 3)
rMat <- matrix(as.logical(rbinom(30, 1, 0.3)), ncol = 3)
tmpTab3[rMat] <- "."
colnames(tmpTab3) <- c("X", "Y", "Z")

patTab3 <- xtable(tmpTab3,
                  align   = rep("c", 4),
                  caption = "Arbitrary Pattern")
@

\begin{columns}[T]
  \begin{column}{0.33\textwidth}

<<echo = FALSE, results = 'asis'>>=
print(patTab1, booktabs = TRUE)
@

\end{column}
\begin{column}{0.33\textwidth}

<<echo = FALSE, results = 'asis'>>=
print(patTab2, booktabs = TRUE)
@

\end{column}
\begin{column}{0.33\textwidth}

<<echo = FALSE, results = 'asis'>>=
print(patTab3, booktabs = TRUE)
@

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Nonresponse Rates}

  \rmsc{Proportion Missing}
  %\begin{align*}
  %  PM_p = N^{-1} \sum_{n = 1}^N r_{np}
  %\end{align*}
  \begin{itemize}
  \item The proportion of cells containing missing data
  \item Good early screening measure
  \item Should be computed for each variable, not for the entire dataset
  \end{itemize}

  \va

  \rmsc{Attrition Rate}
  \begin{itemize}
  \item The proportion of participants that drop-out of a study at each
    measurement occasion
  \end{itemize}

  \pagebreak

  \rmsc{Proportion of Complete Cases}
  \begin{itemize}
  \item The proportion of observations with no missing data
  \item Often reported but nearly useless quantity
  \end{itemize}

  \va

  \rmsc{Fraction of Missing Information}
  \begin{itemize}
  \item Associated with an estimated parameter, not with an incomplete variable
  \item Like an $R^2$ for the missing data
  \item Most important diagnostic value for missing data problems
  \item Can only be computed after treating the missing data
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Coverage Measures}

  \rmsc{Covariance Coverage}
  \begin{align*}
    CC_{jk} = N^{-1} \sum_{n = 1}^N r_{nj}r_{nk}
  \end{align*}
  \begin{itemize}
  \item The proportion of cases available to estimate a given pairwise
    relationship (e.g., a covariance between two variables)
  \item Very important to have adequate coverage of the parameters you
    want to estimate
  \end{itemize}

  \pagebreak

  \rmsc{Inbound Statistic}
  \begin{align*}
    I_{jk} = \frac{\sum_{n = 1}^N (1 - r_{nj})r_{nk}}{\sum_{n = 1}^N (1 - r_{nj})}
  \end{align*}
  \begin{itemize}
  \item The proportion of missing cases in $Y_{j}$ for which $Y_{k}$ is observed
  \end{itemize}

  \va

  \rmsc{Outbound Statistic}
  \begin{align*}
    O_{jk} = \frac{\sum_{n = 1}^N r_{nj}(1 - r_{nk})}{\sum_{n = 1}^N r_{nj}}
  \end{align*}
  \begin{itemize}
  \item The proportion of observed cases in $Y_{j}$ for which $Y_{k}$ is missing
  \end{itemize}

  \pagebreak

  \rmsc{Influx Coefficient}
  \begin{align*}
    I_j = \frac{\sum_{k = 1}^P \sum_{n = 1}^N (1 - r_{nj})r_{nk}}{\sum_{k = 1}^P \sum_{n = 1}^N r_{nk}}
  \end{align*}
  \begin{itemize}
  \item The proportion of observed cells in $Y$ that exists in cases for which
    $Y_j$ is missing
  \item How well the missing values in $Y_j$ connect to the observed values in
    $Y_{-j}$
  \end{itemize}

  \pagebreak

  \rmsc{Outflux Coefficient}
  \begin{align*}
    O_j = \frac{\sum_{k = 1}^P \sum_{n = 1}^N r_{nj}(1 - r_{nk})}{\sum_{k = 1}^P \sum_{n = 1}^N (1 - r_{nk})}
  \end{align*}
  \begin{itemize}
  \item The proportion of missing cells in $Y$ that exists in cases for which
    $Y_j$ is observed
  \item How well the observed values in $Y_j$ connect to the missing values in
    $Y_{-j}$
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Examples}

  \begin{columns}
    \begin{column}{0.61\textwidth}

      \begin{enumerate}
      \item What is the coverage for $cov(X, Y)$?
        \vb
      \item What is the coverage for $cov(W, Y)$?
        \vb
      \item What is the coverage for $cov(X, Z)$?
        \vb
      \item What is the outflux coefficient for $W$?
        \vb
      \item What is the influx coefficient for $W$?
      \end{enumerate}

    \end{column}
    \begin{column}{0.39\textwidth}

<<echo = FALSE, results = 'asis'>>=
tmpTab4 <- matrix(c(rep("w", 10),
                    rep("x", 5), rep(".", 5),
                    rep("y", 10),
                    rep(".", 5), rep("z", 5)),
                 ncol = 4)
colnames(tmpTab4) <- c("W", "X", "Y", "Z")

patTab4 <- xtable(tmpTab4, align = rep("c", 5))
print(patTab4, booktabs = TRUE)
@

\end{column}
\end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Examples}

  \begin{columns}
    \begin{column}{0.6\textwidth}

      \begin{enumerate}
        \item What is the percent missing at T2?
          \vb
        \item What is the attrition rate at T3?
          \vb
        \item What is the inbound statistic $I_{32}$?
          \vb
        \item What is the outbound statistic $O_{42}$?
          \vb
        \item What is the influx coefficient $I_3$?
          \vb
        \item What is the outflux coefficient $O_2$?
      \end{enumerate}

    \end{column}
    \begin{column}{0.4\textwidth}

<<echo = FALSE, results = 'asis'>>=
tmpTab5 <- matrix(c(rep("x1", 10),
                    rep("x2", 7), rep(".", 3),
                    rep("x3", 5), rep(".", 5),
                    rep("x4", 3), rep(".", 7)),
                 ncol = 4)
colnames(tmpTab5) <- c("T1", "T2", "T3", "T4")

patTab5 <- xtable(tmpTab5, align = rep("c", 5))
print(patTab5, booktabs = TRUE)
@

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\sectionslide{Missing Data Mechanisms}

%------------------------------------------------------------------------------%

\begin{frame}{Missing Data Mechanisms}

  Missing Completely at Random (MCAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) = P(R)$
    \vc
  \item Missingness is unrelated to any study variables.
  \end{itemize}
  \vb
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) = P(R)
  %\end{align*}

  Missing at Random (MAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) = P(R | Y_{obs})$
    \vc
  \item Missingness is related to only the \emph{observed} parts of study
      variables.
  \end{itemize}
  \vb
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) = P(R | Y_{obs})
  %\end{align*}

  Missing not at Random (MNAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) \neq P(R | Y_{obs})$
    \vc
  \item Missingness is related to the \emph{unobserved} parts of study
    variables.
  \end{itemize}
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) \neq P(R | Y_{obs})
  %\end{align*}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Simulate Some Toy Data}

<<>>=
nObs <- 5000 # Sample Size
pm   <- 0.3  # Proportion Missing

sigma <- matrix(c(1.0, 0.5, 0.3,
                  0.5, 1.0, 0.0,
                  0.3, 0.0, 1.0),
                ncol = 3)
tmp <- rmvnorm(nObs, c(0, 0, 0), sigma)

x0 <- tmp[ , 1]
y0 <- tmp[ , 2]
z0 <- tmp[ , 3]

cor(y0, x0) # Check correlation between X and Y
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MCAR Example}

<<>>=
## Simulate MCAR Missingness:
mVec <- sample(1 : length(y0), size = pm * length(y0))

yMcar       <- y0
yMcar[mVec] <- NA

cor(yMcar, x0, use = "pairwise") # Look at correlation
@

\pagebreak

<<echo = FALSE, out.width = "65%">>=
y0Den <- density(y0)
yDen  <- density(yMcar, na.rm = TRUE)

pDat <- data.frame(y = c(y0Den$y, yDen$y),
                   x = c(y0Den$x, yDen$x),
                   g = rep(c("Complete", "MCAR w/ Deletion"),
                           each = length(yDen$y)
                           )
                   )

ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
    geom_line(size = 1) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16)) +
    ylab("Density") +
    xlab("Value of Y") +
    scale_color_manual(values = c("blue", "red")) +
    theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MAR Example}

<<>>=
## Simulate MAR Missingness:
mVec <- x0 < quantile(x0, probs = pm)
mean(mVec)

yMar       <- y0
yMar[mVec] <- NA

cor(yMar, x0, use = "pairwise") # Not looking so good :(
@

\pagebreak

<<echo = FALSE, out.width = "65%">>=
yDen <- density(yMar, na.rm = TRUE)

pDat <- data.frame(y = c(y0Den$y, yDen$y),
                   x = c(y0Den$x, yDen$x),
                   g = rep(c("Complete", "MAR w/ Deletion"),
                           each = length(yDen$y)
                           )
                   )

marP <- ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
    geom_line(size = 1) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16)) +
    ylab("Density") +
    xlab("Value of Y") +
    scale_color_manual(values = c("blue", "red")) +
    theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
marP
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MNAR Example}

<<>>=
## Simulate MNAR Missingness:
mVec <- y0 < quantile(y0, probs = pm)
mean(mVec)

yMnar       <- y0
yMnar[mVec] <- NA

cor(yMnar, x0, use = "pairwise") # Hmm...looks pretty bad.
@

\pagebreak

<<echo = FALSE, out.width = "65%">>=
yDen <- density(yMnar, na.rm = TRUE)

pDat <- data.frame(y = c(y0Den$y, yDen$y),
                   x = c(y0Den$x, yDen$x),
                   g = rep(c("Complete", "MNAR w/ Deletion"),
                           each = length(yDen$y)
                           )
                   )

ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
    geom_line(size = 1) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16)) +
    ylab("Density") +
    xlab("Value of Y") +
    scale_color_manual(values = c("blue", "red")) +
    theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Crucial Nuance}

  In our previous MAR example, ignoring the predictor of missingness actually
  produces \emph{Indirect MNAR}.\\

  \pause
  \va

  \rmsc{Question:} What happens if we ignore the predictor of missingness, but
  that predictor is independent of our study variables?

  \pause

<<>>=
mVec <- z0 < quantile(z0, probs = pm)

y       <- y0
y[mVec] <- NA

cor(y, x0, use = "pairwise")
@

\rmsc{Answer:} We get back to MCAR :)

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Crucial Nuance}

  The missing data mechanisms are not simply characteristics of an incomplete
  dataset; we also need to account for the analysis.
  \vb
  \begin{columns}
    \begin{column}{0.5\textwidth}

<<echo = FALSE, out.width = "100%", message = FALSE>>=
marP + scale_color_manual(values = c("blue", "red"),
                          labels = c("Complete", "Indirect MNAR")
                          )
@

\end{column}
\begin{column}{0.5\textwidth}

<<echo = FALSE, out.width = "100%">>=
yDen <- density(y, na.rm = TRUE)

pDat <- data.frame(y = c(y0Den$y, yDen$y),
                   x = c(y0Den$x, yDen$x),
                   g = rep(c("Complete", "MCAR2"),
                           each = length(yDen$y)
                           )
                   )

ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
    geom_line(size = 1) +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16)) +
    ylab("Density") +
    xlab("Value of Y") +
    scale_color_manual(values = c("blue", "red")) +
    theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
@

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Testing the Missing Data Mechanism}

  We cannot fully test the MAR or MNAR assumptions.
  \begin{itemize}
  \item To do so would require knowing the values of the missing data.
    \vc
  \item We can find observed predictors of missingness, but we can never know
    that we have them all.
    \vc
  \item In practice, MAR and MNAR live on the ends of a continuum.
    \begin{itemize}
    \item Our missing data problem exists at some unknown point along this
      continuum.
      \vc
    \item We can do a lot to nudge our problem towards the MAR side.
    \end{itemize}
  \end{itemize}

  \pagebreak

  We can test the MCAR assumption.
  \begin{itemize}
  \item With MCAR, the missing data and the observed data should have the same
    distribution.
    \vc
  \item We can test for MCAR by testing the distributions of \emph{auxiliary
    variables}, $\mathbf{Z}$.
    \begin{itemize}
    \item Use a t-test to compare the subset of $Z_p$ that corresponds to
      $Y_{mis}$ to the subset corresponding to $Y_{obs}$.
      \vc
    \item The \citet{little:1988} MCAR test is a multivariate version of this.
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  Create some toy datasets from the variables we generated above.

<<>>=
mcarData <- data.frame(y = yMcar, x = x0, z = z0,
                       m = as.numeric(is.na(yMcar))
                       )
marData  <- data.frame(y = yMar, x = x0, z = z0,
                       m = as.numeric(is.na(yMar))
                       )
mnarData <- data.frame(y = yMnar, x = x0, z = z0,
                       m = as.numeric(is.na(yMnar))
                       )
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $X$ and $M_Y$ in MCAR data.

<<>>=
mcarData %$% t.test(x ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $Z$ and $M_Y$ in MCAR data.

<<>>=
mcarData %$% t.test(z ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $X$ and $M_Y$ in MAR data.

<<>>=
marData %$% t.test(x ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $Z$ and $M_Y$ in MAR data.

<<>>=
marData %$% t.test(z ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%
\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $X$ and $M_Y$ in MNAR data.

<<>>=
mnarData %$% t.test(x ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{T-Test Example}

  Test for dependence between $Z$ and $M_Y$ in MNAR data.

<<>>=
mnarData %$% t.test(z ~ m) %>% wrap()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{\citet{little:1988} MCAR Test Example}

  Use the \citet{little:1988} MCAR test on MCAR data.

<<>>=
mcarData %>% select(-m) %>% mcar_test()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{\citet{little:1988} MCAR Test Example}

Use the \citet{little:1988} MCAR test on MAR data.

<<>>=
marData %>% select(-m) %>% mcar_test()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{\citet{little:1988} MCAR Test Example}

Use the \citet{little:1988} MCAR test on MNAR data.

<<>>=
mnarData %>% select(-m) %>% mcar_test()
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Logistic Regression Example}

<<cache = TRUE>>=
## Read in some data:
diabetes1 <- readRDS(paste0(dataDir, "diabetes.rds"))

## Generate MAR missingness:
diabetes1$m <- simLogisticMissingness0(data    = diabetes1,
                                       pm      = 0.25,
                                       preds   = c("bmi", "tc"),
                                       type    = "high",
                                       stdData = TRUE)$r

## Predict the missingness using logistic regression:
fit <- diabetes1 %>%
    select(-glu) %>%
    glm(m ~ ., data = ., family = "binomial")
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Logistic Regression Example}

<<>>=
partSummary(fit, 3)
@

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Missing Data Treatments}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  Listwise Deletion (Complete Case Analysis)
  \begin{itemize}
  \item Use only complete observations for the analysis
    \begin{itemize}
    \item Very wasteful (can throw out lots of useful data)
    \item Loss of statistical power
    \end{itemize}
  \end{itemize}

  \va

  Pairwise Deletion (Available Case Analysis)
  \begin{itemize}
  \item Use only complete pairs of observations for analysis
    \begin{itemize}
    \item Different samples sizes for different parameter estimates
    \item Can cause computational issues
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
<<>>=
diabetes2              <- diabetes1
mVec                   <- with(diabetes2, bmi > quantile(bmi, 0.75))
diabetes2[mVec, "glu"] <- NA

diabetes1 %>% select(bmi, glu, bp) %>% cor()
diabetes2 %>% select(bmi, glu, bp) %>% cor(use = "pairwise")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
mean(diabetes1$glu)
mean(diabetes2$glu, na.rm = TRUE)
var(diabetes1$glu)
var(diabetes2$glu, na.rm = TRUE)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
s2 <- lm(glu ~ bmi + bp + age, data = diabetes2) %>% summary()

s1$r.squared
s2$r.squared
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1$coef
s2$coef
@
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      (Unconditional) Mean Substitution
      \begin{itemize}
      \item Replace $Y_{mis}$ with $\bar{Y}_{obs}$
        \begin{itemize}
        \item Negatively biases regression slopes and correlations
        \item Attenuates measures of linear association
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{

<<echo = FALSE, cache = TRUE>>=
                                        #dat1 <- readRDS(paste0(dataDir, "diabetes.rds"))
          
                                        #mVec <- simSimpleMar(pm      = 0.25,
                                        #                     data    = dat1,
                                        #                     preds   = "bmi",
                                        #                     type    = "high",
                                        #                     stdData = TRUE)

                                        #dat2              <- dat1
                                        #dat2[mVec, "glu"] <- NA

p0 <- ggplot(data = diabetes1, mapping = aes(x = bmi, y = glu)) +
    geom_point() +
    theme_classic() +
    theme(text = element_text(family = "Courier", size = 16)) +
    xlab("BMI") +
    ylab("Blood Glucose")

p0
@

}
      \only<2>{

<<echo = FALSE, cache = TRUE>>=
p1 <- p0 +
    geom_point(data = diabetes2, 
               mapping = aes(y = glu, x = bmi), 
               colour = "blue")

p1
@

}

      \only<3>{

<<echo = FALSE, cache = TRUE>>=
miceM <- mice(data      = diabetes2[ , c("bmi", "glu")],
              m         = 1,
              maxit     = 1,
              method    = "mean",
              printFlag = FALSE)

datM0 <- datM <- complete(miceM, 1)
datM[!mVec, ] <- NA

p2 <- p1 + geom_point(data    = datM,
                      mapping = aes(y = glu, x = bmi),
                      colour  = "red")
p2
@

}

      \only<4>{

<<echo = FALSE, cache = TRUE>>=
p2 + geom_smooth(data    = diabetes1,
                 mapping = aes(y = glu, x = bmi),
                 method  = "lm",
                 color   = "black",
                 se      = FALSE) +
    geom_smooth(data    = datM0,
                mapping = aes(y = glu, x = bmi),
                method  = "lm",
                color   = "red",
                se      = FALSE)
@

}

\end{column}
\end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
<<>>=
diabetes3              <- diabetes2
diabetes3[mVec, "glu"] <- mean(diabetes3$glu, na.rm = TRUE)

diabetes1 %>% select(bmi, glu, bp) %>% cor()
diabetes3 %>% select(bmi, glu, bp) %>% cor(use = "pairwise")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
mean(diabetes1$glu)
mean(diabetes3$glu, na.rm = TRUE)
var(diabetes1$glu)
var(diabetes3$glu, na.rm = TRUE)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
s3 <- lm(glu ~ bmi + bp + age, data = diabetes3) %>% summary()

s1$r.squared
s3$r.squared
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1$coef
s3$coef
@
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      Deterministic Regression Imputation\\
      (Conditional Mean Substitution)
      \begin{itemize}
      \item Replace $Y_{mis}$ with $\widehat{Y}_{mis}$ from some regression
        equation
        \begin{itemize}
        \item Positively biases regression slopes and correlations
        \item Inflates measures of linear association
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{

<<echo = FALSE, cache = TRUE>>=
miceD <- mice(data      = diabetes2[ , c("bmi", "glu")],
              m         = 1,
              maxit     = 1,
              method    = "norm.predict",
              printFlag = FALSE)

datD0 <- datD <- complete(miceD, 1)
datD[!mVec, ] <- NA

p2 <- p1 + geom_point(data = datD,
                      mapping = aes(y = glu, x = bmi),
                      colour = "red")
p2
@

}
      \only<2>{

<<echo = FALSE, cache = TRUE>>=
p2 + geom_smooth(data    = diabetes1,
                 mapping = aes(y = glu, x = bmi),
                 method  = "lm",
                 color   = "black",
                 se      = FALSE) +
    geom_smooth(data    = datD0,
                mapping = aes(y = glu, x = bmi),
                method  = "lm",
                color   = "red",
                se      = FALSE)
@

}

\end{column}
\end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      Deterministic Regression Imputation\\
      (Conditional Mean Substitution)
      \begin{itemize}
      \item Replace $Y_{mis}$ with $\widehat{Y}_{mis}$ from some regression
        equation
        \begin{itemize}
        \item Positively biases regression slopes and correlations
        \item Inflates measures of linear association
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{

<<echo = FALSE, cache = TRUE>>=
miceD <- mice(data      = diabetes2,
              m         = 1,
              maxit     = 1,
              method    = "norm.predict",
              printFlag = FALSE)

datD0 <- datD <- complete(miceD, 1)
datD[!mVec, ] <- NA

p2 <- p1 + geom_point(data = datD,
                      mapping = aes(y = glu, x = bmi),
                      colour = "red")
p2
@

}
      \only<2>{

<<echo = FALSE, cache = TRUE>>=
p2 + geom_smooth(data    = diabetes1,
                 mapping = aes(y = glu, x = bmi),
                 method  = "lm",
                 color   = "black",
                 se      = FALSE) +
    geom_smooth(data    = datD0,
                mapping = aes(y = glu, x = bmi),
                method  = "lm",
                color   = "red",
                se      = FALSE)
@

}

\end{column}
\end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
<<>>=
diabetes3 <- mice(data      = diabetes2, 
                  m         = 1, 
                  maxit     = 1,
                  printFlag = FALSE,
                  method    = "norm.predict") %>% 
    complete(1)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
diabetes1 %>% select(bmi, glu, bp) %>% cor()
diabetes3 %>% select(bmi, glu, bp) %>% cor(use = "pairwise")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
mean(diabetes1$glu)
mean(diabetes3$glu, na.rm = TRUE)
var(diabetes1$glu)
var(diabetes3$glu, na.rm = TRUE)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
s3 <- lm(glu ~ bmi + bp + age, data = diabetes3) %>% summary()

s1$r.squared
s3$r.squared
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

<<>>=
s1$coef
s3$coef
@
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{center}
    \ovalbox{General Issues with Deletion-Based Methods}
  \end{center}

  \begin{itemize}
  \item Biased parameter estimates unless data are MCAR
  \item Generalizability issues
  \end{itemize}

  \va

  \begin{center}
    \ovalbox{General Issues with Simple Single Imputation Methods}
  \end{center}

  \begin{itemize}
  \item Biased parameter estimates even when data are MCAR
  \item Attenuates variability in any treated variables
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  Averaging Available Items (Person-Mean Imputation)
  \begin{itemize}
  \item Compute aggregate scores using only available values
    \begin{itemize}
    \item Missing data must be MCAR
    \item Each item must contributes equally to the aggregate score
    \end{itemize}
  \end{itemize}

  \vb

  Last Observation Carried Forward (LOCF)
  \begin{itemize}
  \item Replace post-dropout values with the most recent observed value
    \begin{itemize}
    \item Assume that dropouts would maintain their last known values
    \item Attenuates estimates of growth/development
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{LOCF}

<<echo = FALSE, cache = TRUE>>=
## Simulate some longitudinal data with random slopes:
n1 <- 5
n2 <- 50

s     <- 1.0
gamma <- c(1.5, 1.25)
tau   <- matrix(c(1.0, -0.3, -0.3, 1.0), 2, 2)

U    <- rmvnorm(n2, gamma, tau)
time <- matrix(1:n1 - 1)
tmp  <- U[ , 1] + U[ , 2] %*% t(time)

dat1 <- dat2 <- dat3 <-
    data.frame(y = as.numeric(tmp) + rnorm(n1 * n2, 0, s),
               t = rep(0:(n1 - 1), each = n2),
               id = rep(1:n2, n1)
               ) %>%
    arrange(id)

## Apply random attrition:
dat2$y <- dat1 %$% tapply(y, id, attrit, pComp = 0.25) %>% unlist()

## Treat attrition with LOCF:
dat3$y <- dat2 %$% tapply(y, id, locf) %>% unlist()

## Create some missingness indicators for plotting purposes:
dat3$m  <- is.na(dat2$y)
dat3$m2 <- dat3 %$% tapply(m,
                           id,
                           function(x) {
                               tmp <- (which(x) - 1)[1]
                               x[tmp] <- TRUE
                               x
                           }
                           ) %>% unlist()

p0 <- ggplot(data = dat1, mapping = aes(y = y, x = t)) +
    ylab("Y") +
    xlab("Time") +
    theme(plot.title = element_text(family = "serif", 
                                    face = "bold", 
                                    hjust = 0.5)
          )

p1 <- p0 + scale_color_manual(values = c("black", "red")) +
    theme(legend.position = "none") +
    ylim(range(dat1$y))
@ 

\only<1>{
  
<<echo = FALSE, cache = TRUE, fig.asp = 0.5>>=
ggarrange(
    p0 + 
    geom_line(aes(group = id), alpha = 0.3) + geom_point() +
    ggtitle("Fully Observed Data"),
    
    p0 + 
    geom_line(data = dat2, mapping = aes(group = id), alpha = 0.3) +
    geom_point(data = dat2) +
    ylim(range(dat1$y)) +
    ggtitle("Data with Attrition"),
    
    ncol = 2
)
@

}

\only<2>{
  
<<echo = FALSE, cache = TRUE, fig.asp = 0.5>>=
ggarrange(
    p1 + 
    geom_line(data = dat3, aes(group = id, color = m2), alpha = 0.3) +
    geom_point(data = dat3, aes(color = m)) +
    ggtitle("Data Treated with LOCF"),
    
    p1 + 
    geom_line(data = dat3, aes(group = id, color = m2), alpha = 0.1) +
    geom_point(data = dat3, aes(color = m), alpha = 0.1) +
    geom_smooth(data = dat3,
                method = "lm",
                se = FALSE,
                color = "red",
                size = 1) +
    geom_smooth(data = dat1,
                method = "lm",
                se = FALSE,
                color = "black",
                size = 1) +
    ggtitle("Correct vs. Imputed Trends"),
    
    ncol = 2
)
@

}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
<<>>=
## Fit some multilevel regression models
fit1 <- lmer(y ~ t + (t | id), data = dat1) # Full data
fit2 <- lmer(y ~ t + (t | id), data = dat3) # LOCF data
@ 

<<echo = FALSE, fig.asp = 0.5>>=
rf1 <- ranef(fit1)[[1]]
rf2 <- ranef(fit2)[[1]]

rf <- data.frame(Data = rep(c("Full", "LOCF"), each = nrow(rf1)),
                 x = c(rf1$t, rf2$t)
                 )

ff1 <- coef(fit1)[[1]]
ff2 <- coef(fit2)[[1]]

ff <- data.frame(Data = rep(c("Full", "LOCF"), each = nrow(ff1)),
                 x = c(ff1$t, ff2$t)
                 )

ggarrange(
    ggplot(data = rf, mapping = aes(x = x, color = Data)) + 
    geom_density() +
    ylab("Density") +
    xlab("Random Effect") +
    ggtitle("Distributions of Random Effects") +
    scale_color_manual(values = c("black", "red")) +
    theme_classic() +
    theme(plot.title = element_text(family = "serif", 
                                    face = "bold", 
                                    hjust = 0.5)
          ),
    
    ggplot(data = ff, mapping = aes(x = x, color = Data)) + 
    geom_density() +
    ylab("Density") +
    xlab("Fixed Effect") +
    ggtitle("Distributions of Fixed Effects") +
    scale_color_manual(values = c("black", "red")) +
    theme_classic() +
    theme(plot.title = element_text(family = "serif", 
                                    face = "bold", 
                                    hjust = 0.5)
          ),
    
    ncol = 2,
    common.legend = TRUE,
    legend = "right"
)
@
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{OK Methods (These work in some situations)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      Stochastic Regression Imputation
      \vc
      \begin{itemize}
      \item Fill $Y_{mis}$ with $\widehat{Y}_{mis}$ plus some random noise.
        \vc
        \begin{itemize}
        \item Produces unbiased parameter estimates and predictions
          \vc
        \item Computationally efficient
          \vc
        \item Attenuates standard errors
          \vc
        \item Makes CIs and prediction intervals too narrow
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{

<<echo = FALSE, cache = TRUE, warning = FALSE>>=
miceS <- mice(data      = dat2[ , c("bmi", "glu")],
              m         = 1,
              maxit     = 10,
              method    = "norm.nob",
              printFlag = FALSE)

datS0 <- datS <- complete(miceS, 1)
datS[!mVec, ] <- NA

p2 <- p1 + geom_point(data = datS,
                      mapping = aes(y = glu, x = bmi),
                      colour = "red")
p2
@

}
      \only<2>{

<<echo = FALSE, cache = TRUE>>=
p2 + geom_smooth(data    = dat1,
                 mapping = aes(y = glu, x = bmi),
                 method  = "lm",
                 color   = "black",
                 se      = FALSE) +
    geom_smooth(data    = datD0,
                mapping = aes(y = glu, x = bmi),
                method  = "lm",
                color   = "red",
                se      = FALSE)
@

}

\end{column}
\end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{OK Methods (These work in some situations)}

  Nonresponse Weighting
  \vc
  \begin{itemize}
  \item Weight the observed cases to correct for nonresponse bias
    \vc
    \begin{itemize}
    \item Popular in survey research and official statistics
      \vc
    \item Only worth considering with \emph{Unit Nonresponse}
      \vc
    \item Doesn't make any sense with \emph{Item Nonresponse}
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Expectation Maximization}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Good Methods (These almost always work)}

  Multiple Imputation (MI)
  \vc
  \begin{itemize}
  \item Replace the missing values with $M$ plausible estimates
    \vc
    \begin{itemize}
    \item Essentially, a repeated application of stochastic regression
      imputation (with a particular type of regression model)
      \vc
    \item Produces unbiased parameter estimates and predictions
      \vc
    \item Produces ``correct'' standard errors, CIs, and prediction intervals
      \vc
    \item Very, very flexible
      \vc
    \item Computationally expensive
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[allowframebreaks, fragile]{Good Methods (These almost always
    work)}

  What happens when we apply MI to our previous MAR example?
<<>>=
## Estimate imputation model:
miceOut1 <- mice(data      = data.frame(y3, x),
                 m         = 100,
                 maxit     = 1,
                 method    = c("norm", ""),
                 printFlag = FALSE)

## Replace missing values with imputations:
impList1 <- list()
for(m in 1 : miceOut1$m)
    impList1[[m]] <- complete(miceOut1, m)
@

\pagebreak

<<>>=
## Estimate M correlations:
corList <-lapply(impList1,
                 FUN = function(impDat)
                     cor(impDat$x, impDat$y3)
                 )

## Pool estimates:
mean(unlist(corList))
@

The MI-based parameter estimate looks good.
\begin{itemize}
\item MI produces unbiased estimates of the parameter when data are MAR.
\end{itemize}

\pagebreak

<<echo = FALSE, out.width = "65%">>=
yDen <- density(y)

impDen <- list()
for(m in 1 : 100)
    impDen[[m]] <- density(impList1[[m]]$y3)

impRangeY <- range(unlist(lapply(impDen, FUN = function(den){den$y})))
impRangeX <- range(unlist(lapply(impDen, FUN = function(den){den$x})))

yLim <- range(c(yDen$y, impRangeY))
xLim <- range(c(yDen$x, impRangeX))

plot(yDen,
     ylim = yLim,
     xlim = xLim,
     main = "Density Plot of Y",
     xlab = "Value of Y")

for(m in 1 : 100) {
    impDen <- density(impList1[[m]]$y3)
    lines(impDen, col = "red")
}

lines(yDen, lwd = 2)

legend(x      = "topright",
       legend = c("Complete", "MAR w/ MI"),
       col    = c("black", "red"),
       lty    = 1,
       lwd    = 1,
       cex    = 0.75)
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Good Methods (These almost always work)}

  What about applying MI to our MNAR example?
<<>>=
## Estimate imputation model:
miceOut2 <- mice(data      = data.frame(y4, x),
                 m         = 100,
                 maxit     = 1,
                 method    = c("norm", ""),
                 printFlag = FALSE)

## Replace missing values with imputations:
impList2 <- list()
for(m in 1 : miceOut2$m)
    impList2[[m]] <- complete(miceOut2, m)
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks, fragile]{Good Methods (These \emph{almost}
    always work)}

<<>>=
## Estimate M correlations:
corList2 <-lapply(impList2,
                 FUN = function(impDat)
                     cor(impDat$x, impDat$y4)
                 )

## Pool estimates:
mean(unlist(corList2))
@

The MI-based parameter estimate is still biased.
\begin{itemize}
\item MI cannot correct bias in parameter estimates when data are MNAR.
\end{itemize}

\pagebreak

<<echo = FALSE, out.width = "65%">>=
y4Den <- density(y4, na.rm = TRUE)

impDen <- list()
for(m in 1 : 100)
    impDen[[m]] <- density(impList2[[m]]$y4)

impRangeY <- range(unlist(lapply(impDen, FUN = function(den){den$y})))
impRangeX <- range(unlist(lapply(impDen, FUN = function(den){den$x})))

yLim <- range(c(yDen$y, impRangeY))
xLim <- range(c(yDen$x, impRangeX))

plot(yDen,
     ylim = yLim,
     xlim = xLim,
     main = "Density Plot of Y",
     xlab = "Value of Y")

for(m in 1 : 100) {
    impDen <- density(impList2[[m]]$y4)
    lines(impDen, col = "blue")
}

lines(yDen, lwd = 2)
lines(y4Den, col = "red", lwd = 2)

legend(x      = "topright",
       legend = c("Complete", "MNAR w/ Deletion", "MNAR w/ MI"),
       col    = c("black", "red", "blue"),
       lty    = 1,
       lwd    = 1,
       cex    = 0.75)
@

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Good Methods (These almost always work)}

  Bayesian Modeling
  \vc
  \begin{itemize}
  \item Treat missing values as just another parameter to be estimated
    \vc
    \begin{itemize}
    \item Models can be directly estimated in the presence of missing data
      \begin{itemize}
      \item Essentially, runs MI behind-the-scenes during model estimation
      \end{itemize}
      \vc
    \item The predictors of nonresponse must be included in the model, somehow
      \vc
    \item Computationally expensive
    \end{itemize}
  \end{itemize}

  \pagebreak

  Full Information Maximum Likelihood (FIML)
  \vc
  \begin{itemize}
  \item Adjust the objective function to only consider the observed parts of the
    data
    \vc
    \begin{itemize}
    \item Models are directly estimated in the presence of missing data
      \vc
    \item The predictors of nonresponse must be included in the model, somehow
      \vc
    \item Unless you write your own optimization program, FIML is only available
      for certain types of models
      \vc
    \item In linear regression models, FIML cannot treat missing data on
      predictors (if the predictors are taken as fixed)
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{References}

  \bibliographystyle{apacite}
  \bibliography{../../../literature/bibtex/statMethRefs.bib}

\end{frame}

%------------------------------------------------------------------------------%

\end{document}
