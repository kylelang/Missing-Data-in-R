%%% Title:    Missing Data in R: Multivariate MI
%%% Author:   Kyle M. Lang
%%% Created:  2017-09-12
%%% Modified: 2022-01-25

\documentclass[10pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\makeatletter
\@ifundefined{AddToHook}{}{\AddToHook{package/xcolor/after}{\definecolor{fgcolor}{rgb}{0, 0, 0}}}
\makeatother
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\makeatletter
\@ifundefined{AddToHook}{}{\AddToHook{package/xcolor/after}{
\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
}}
\makeatother
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{eurosym}
\usepackage{caption}

\captionsetup{labelformat = empty}

\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}


\title{Multivariate Multiple Imputation}
\subtitle{Utrecht University Winter School: Missing Data in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{2022-02-03}

%------------------------------------------------------------------------------%

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}



%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\section{Flavors of MI}

%------------------------------------------------------------------------------%

\begin{frame}{Joint Modeling vs. Fully Conditional Specification}

  When imputing with \emph{Joint Modeling} (JM) approaches, the missing data are 
  replaced by samples from the joint posterior predictive distribution.
  \vb
  \begin{itemize}
    \item To impute $X$, $Y$, and $Z$, we draw:
      \begin{align*}
        X, Y, Z \sim P(X, Y, Z | \theta)
      \end{align*}
  \end{itemize}
  \vb
  With \emph{Fully Conditional Specification} (FCS), the missing data are 
  replaced with samples from the conditional posterior predictive distribution 
  of each incomplete variable.
  \vb
  \begin{itemize}
  \item To impute $X$, $Y$, and $Z$, we draw:
    \begin{align*}
      X &\sim P(X | Y, Z, \theta_X)\\
      Y &\sim P(Y | X, Z, \theta_Y)\\
      Z &\sim P(Z | Y, X, \theta_Z)
    \end{align*}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Joint Modeling: Strengths}
  
  When correctly implemented, JM approaches are guaranteed to produce 
  \emph{Bayesianly proper} imputations.
  \vb
  \begin{itemize}
  \item A sufficient condition for \emph{properness} is that the imputations 
    are randomly sampled from the correctly specified joint posterior predictive 
    distribution of the missing data.
    \vc
    \begin{itemize}
    \item This is the defining characteristic of JM methods.
    \end{itemize}
  \end{itemize}
  \va
  When using the correct distribution, imputations produced by JM methods will 
  be the best possible imputations.
  \begin{itemize}
  \item Unbiased parameter estimates
  \item Well-calibrated sampling variability
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Joint Modeling: Weaknesses}
  
  JM approaches don't scale well.
  \vc
  \begin{itemize}
  \item The computational burden increases with the number of incomplete 
    variables.
  \end{itemize}
  \va
  JM approaches are only applicable when the joint distribution of all 
  incomplete variables follows a known form.
  \vc
  \begin{itemize}
  \item Mixes of continuous and categorical variables are difficult to 
    accommodate.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Software Implementations}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Fully Conditional Specification: Strengths}
  
  FCS scales much better than JM.
  \vc
  \begin{itemize}
  \item FCS only samples from a series of univariate distributions, not large 
    joint distributions.
  \end{itemize}
  \va 
  FCS approaches can create imputations for variables that don't have a sensible 
  joint distribution.
  \vc
  \begin{itemize}
  \item FCS can easily treat mixes of continuous and categorical variables.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Fully Conditional Specification: Weaknesses}

  FCS will usually be slower than JM.
  \vc
  \begin{itemize}
  \item Each variable gets its own fully parameterized distribution, even if 
    that granularity is unnecessary.
  \end{itemize}
  \va
  When the incomplete variables don't have a known joint distribution, FCS 
  doesn't have theoretical support.
  \vc
  \begin{itemize}
  \item There is, however, a large degree of empirical support for the 
    tenability of the FCS approach.
  \item In practice, we usually choose FCS since real data rarely arise from a 
    known joint distribution.
  \end{itemize}
  
\end{frame}
  
%------------------------------------------------------------------------------%

\begin{frame}{Software Implementations}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Up to this point, most of the models we've explored could be approximated by 
  sampling directly from their posterior distributions.
  \vc
  \begin{itemize}
    \item This won't be true with arbitrary, multivariate missing data.
  \end{itemize}
  \va 
  To make inference regarding a multivariate distribution with multiple, 
  interrelated, unknown parameters, we can use \emph{Gibbs sampling}.
  \vc
  \begin{itemize}
  \item Sample from the conditional distribution of each parameter, conditioning 
    on the current best guesses of all other parameters.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Suppose the following:
  \vb
  \begin{enumerate}
  \item I want to make some inference about the tri-variate mean of
    $X, Y, Z = \mu_X, \mu_Y, \mu_Z \sim P(\mu | \theta)$
    \vb
  \item $P(\mu | \theta)$ is super hairy and difficult to sample
    \vb
  \item I can easily sample from the conditional distributions:
    $P(\mu_X | \hat{\mu}_Y, \hat{\mu}_Z, \theta)$,
    $P(\mu_Y | \hat{\mu}_X, \hat{\mu}_Z, \theta)$, and
    $P(\mu_Z | \hat{\mu}_X, \hat{\mu}_Y, \theta)$.
  \end{enumerate}
  \va
  Then, I can approximate the full joint distribution $P(\mu | \theta)$ by 
  sequentially sampling from
  $P(\mu_X | \hat{\mu}_Y, \hat{\mu}_Z, \theta)$, 
  $P(\mu_Y | \hat{\mu}_X, \hat{\mu}_Z, \theta)$, and 
  $P(\mu_Z | \hat{\mu}_X, \hat{\mu}_Y, \theta)$.

\end{frame}
  
%------------------------------------------------------------------------------%

\begin{frame}{Aside: Gibbs Sampling}
  
  Starting with initial guesses of $\mu_Y$, $\hat{\mu}_Y^{(0)}$, and
  $\mu_Z$, $\hat{\mu}_Z^{(0)}$, and assuming $\theta$ is known, Gibbs
  sampling proceeds as follows:
  \begin{align*}
    \hat{\mu}_X^{(1)} &\sim P(\mu_X | \hat{\mu}_Y^{(0)}, \hat{\mu}_Z^{(0)}, \theta)\\
    \hat{\mu}_Y^{(1)} &\sim P(\mu_Y | \hat{\mu}_X^{(1)}, \hat{\mu}_Z^{(0)}, \theta)\\
    \hat{\mu}_Z^{(1)} &\sim P(\mu_Z | \hat{\mu}_Y^{(1)}, \hat{\mu}_X^{(1)}, \theta)\\
    \\
    \hat{\mu}_X^{(2)} &\sim P(\mu_X | \hat{\mu}_Y^{(1)}, \hat{\mu}_Z^{(1)}, \theta)\\
    \hat{\mu}_Y^{(2)} &\sim P(\mu_Y | \hat{\mu}_X^{(2)}, \hat{\mu}_Z^{(1)}, \theta)\\
    \hat{\mu}_Z^{(2)} &\sim P(\mu_Z | \hat{\mu}_Y^{(2)}, \hat{\mu}_X^{(2)}, \theta)
  \end{align*}
  \vspace{-40pt}
  \begin{center}\huge{$\vdots$}\end{center}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Why do we care?}
  
  Multivariate MI employs the same logic as Gibbs sampling.
  \vb
  \begin{itemize}
  \item The imputations are created by conditioning on the current estimates of 
    the imputation model parameters.
    \vb
  \item The imputation model parameters are updated by conditioning on the most 
    recent imputations.
    \vb
  \item With FCS, each variable is imputed by conditioning on the most recent 
    imputations of all other variables.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Fully Conditional Specification}

%------------------------------------------------------------------------------%

\begin{frame}{Procedure: Fully Conditional Specification}
  
  \begin{enumerate}
  \item Fill the missing data with reasonable guesses.
    \vb
  \item For each incomplete variable, do a single iteration of univariate 
    Bayesian MI (e.g., as seen in the last set of slides). \label{eiStep}
    \vb
    \begin{itemize}
    \item After each variable on the data set is so treated, we've completed one 
      iteration.
    \end{itemize}
    \vc
  \item Repeat Step \ref{eiStep} many times.
    \vb
  \item After the imputation model parameters stabilize, save $M$ imputed data 
    sets.
  \end{enumerate}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Simulate some data:}
\hlstd{simData} \hlkwb{<-}
    \hlkwd{simCovData}\hlstd{(}\hlkwc{nObs} \hlstd{=} \hlnum{1000}\hlstd{,} \hlkwc{sigma} \hlstd{=} \hlnum{0.25}\hlstd{,} \hlkwc{nVars} \hlstd{=} \hlnum{4}\hlstd{)}

\hlkwd{head}\hlstd{(simData,} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
            x1         x2          x3          x4
1   0.06313632 -1.4057704 -0.01709217  1.47929405
2  -1.31592547  1.2970920 -0.83500777 -0.44528158
3  -0.30997023  0.9782580  0.02731853  0.35507390
4   0.06927787  0.1836032  0.68794409  0.08049987
5  -0.99354894 -0.3038956  0.80918329 -1.72143555
6   0.36828016 -0.9423245  1.05155348 -0.11078496
7   1.33333163  2.3089780  1.47203000  0.85877495
8  -0.02759718  0.1714383  0.18927909  0.28627771
9   2.37929433  2.5080935  2.18344726  1.56980951
10  0.31841502  0.7886025  0.73658136  0.39445970
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Example: Fully Conditional Specification}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Impose missing:}
\hlstd{targets}  \hlkwb{<-} \hlkwd{paste0}\hlstd{(}\hlstr{"x"}\hlstd{,} \hlnum{1}\hlopt{:}\hlnum{3}\hlstd{)}
\hlstd{missData} \hlkwb{<-} \hlkwd{imposeMissData}\hlstd{(}\hlkwc{data}    \hlstd{= simData,}
                           \hlkwc{targets} \hlstd{= targets,}
                           \hlkwc{preds}   \hlstd{=} \hlstr{"x4"}\hlstd{,}
                           \hlkwc{pm}      \hlstd{=} \hlnum{0.3}\hlstd{,}
                           \hlkwc{types} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"low"}\hlstd{,} \hlstr{"center"}\hlstd{,} \hlstr{"high"}\hlstd{)}
                           \hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\pagebreak

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{head}\hlstd{(missData,} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
           x1         x2          x3          x4
1          NA -1.4057704 -0.01709217  1.47929405
2  -1.3159255  1.2970920          NA -0.44528158
3  -0.3099702         NA  0.02731853  0.35507390
4          NA  0.1836032  0.68794409  0.08049987
5  -0.9935489 -0.3038956  0.80918329 -1.72143555
6   0.3682802 -0.9423245          NA -0.11078496
7   1.3333316  2.3089780          NA  0.85877495
8          NA         NA  0.18927909  0.28627771
9          NA         NA          NA  1.56980951
10         NA  0.7886025  0.73658136  0.39445970
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Define iteration numbers:}
\hlstd{nImps} \hlkwb{<-} \hlnum{100}
\hlstd{nBurn} \hlkwb{<-} \hlnum{500}
\hlstd{nSams} \hlkwb{<-} \hlstd{nBurn} \hlopt{+} \hlstd{nImps}

\hlcom{## Summarize missingness:}
\hlstd{rMat} \hlkwb{<-} \hlopt{!}\hlkwd{is.na}\hlstd{(missData)}
\hlstd{nObs} \hlkwb{<-} \hlkwd{colSums}\hlstd{(rMat)}
\hlstd{nMis} \hlkwb{<-} \hlkwd{colSums}\hlstd{(}\hlopt{!}\hlstd{rMat)}

\hlcom{## Fill the missingness with initial (bad) guesses:}
\hlstd{mean0}  \hlkwb{<-} \hlkwd{colMeans}\hlstd{(missData,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlstd{sigma0} \hlkwb{<-} \hlkwd{cov}\hlstd{(missData,} \hlkwc{use} \hlstd{=} \hlstr{"pairwise"}\hlstd{)}
\hlstd{draws0} \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlkwd{nrow}\hlstd{(missData), mean0, sigma0)}

\hlstd{impData}        \hlkwb{<-} \hlstd{missData}
\hlstd{impData[}\hlopt{!}\hlstd{rMat]} \hlkwb{<-} \hlstd{draws0[}\hlopt{!}\hlstd{rMat]}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Define an elementary imputation function:
  
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{eif} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{rVec}\hlstd{,} \hlkwc{v}\hlstd{) \{}
    \hlcom{## Get the expected betas:}
    \hlstd{fit}  \hlkwb{<-} \hlkwd{lm}\hlstd{(}\hlkwd{paste}\hlstd{(v,} \hlstr{"~ ."}\hlstd{),} \hlkwc{data} \hlstd{= data[rVec, ])}
    \hlstd{beta} \hlkwb{<-} \hlkwd{coef}\hlstd{(fit)}

    \hlcom{## Sample sigma:}
    \hlstd{sigScale} \hlkwb{<-} \hlstd{(}\hlnum{1} \hlopt{/} \hlstd{fit}\hlopt{$}\hlstd{df)} \hlopt{*} \hlkwd{crossprod}\hlstd{(}\hlkwd{resid}\hlstd{(fit))}
    \hlstd{sigmaSam} \hlkwb{<-} \hlkwd{rinvchisq}\hlstd{(}\hlnum{1}\hlstd{,} \hlkwc{df} \hlstd{= fit}\hlopt{$}\hlstd{df,} \hlkwc{scale} \hlstd{= sigScale)}

    \hlcom{## Sample beta:}
    \hlstd{betaVar} \hlkwb{<-} \hlstd{sigmaSam} \hlopt{*} \hlkwd{solve}\hlstd{(}\hlkwd{crossprod}\hlstd{(}\hlkwd{qr.X}\hlstd{(fit}\hlopt{$}\hlstd{qr)))}
    \hlstd{betaSam} \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlnum{1}\hlstd{,} \hlkwc{mean} \hlstd{= beta,} \hlkwc{sigma} \hlstd{= betaVar)}

    \hlcom{## Return a randomly sampled imputation:}
    \hlkwd{matrix}\hlstd{(}\hlkwd{cbind}\hlstd{(}\hlnum{1}\hlstd{, data[}\hlopt{!}\hlstd{rVec, ]))} \hlopt{%*%} \hlstd{betaSam} \hlopt{+}
        \hlkwd{rnorm}\hlstd{(}\hlkwd{sum}\hlstd{(}\hlopt{!}\hlstd{rVec),} \hlnum{0}\hlstd{,} \hlkwd{sqrt}\hlstd{(sigmaSam))}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Apply the elementary imputation function to each incomplete variable:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Iterate through the FCS algorithm:}
\hlstd{impList} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(s} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nSams) \{}
    \hlkwa{for}\hlstd{(v} \hlkwa{in} \hlstd{targets) \{}
        \hlstd{rVec}              \hlkwb{<-} \hlstd{rMat[ , v]}
        \hlstd{impData[}\hlopt{!}\hlstd{rVec, v]} \hlkwb{<-} \hlkwd{eif}\hlstd{(impData, rVec, v)}
    \hlstd{\}}

    \hlcom{## If the chains are burnt-in, save imputed datasets:}
    \hlkwa{if}\hlstd{(s} \hlopt{>} \hlstd{nBurn) impList[[s} \hlopt{-} \hlstd{nBurn]]} \hlkwb{<-} \hlstd{impData}
\hlstd{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in matrix(cbind(1, data[!rVec, ])) \%*\% betaSam: requires numeric/complex matrix/vector arguments}}\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Fully Conditional Specification}
  
  Analyze the multiply imputed datasets:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## First, our manual version:}
\hlstd{fits1} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,} \hlkwc{data} \hlstd{= x)}
                \hlstd{)}
\hlstd{pool1} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits1)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in variances[[1]]: subscript out of bounds}}\begin{alltt}
\hlcom{## Do the same analysis with mice():}
\hlstd{miceOut} \hlkwb{<-} \hlkwd{mice}\hlstd{(}\hlkwc{data}      \hlstd{= missData,}
                \hlkwc{m}         \hlstd{=} \hlnum{100}\hlstd{,}
                \hlkwc{method}    \hlstd{=} \hlstr{"norm"}\hlstd{,}
                \hlkwc{printFlag} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\hlstd{fits2} \hlkwb{<-} \hlkwd{with}\hlstd{(miceOut,} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3))}
\hlstd{pool2} \hlkwb{<-} \hlkwd{pool}\hlstd{(fits2)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Example: Fully Conditional Specification}

  Compare approaches:\\
  \vb
  
\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in coef(pool1): object 'pool1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in vcov(pool1): object 'pool1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'cf1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in pt(t1, df1, lower.tail = FALSE): object 't1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in cbind(cf1, se1, t1, p1, fmi1): object 'cf1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in colnames(res1) <- c("{}Est"{}, "{}SE"{}, "{}t"{}, "{}p"{}, "{}FMI"{}): object 'res1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'res1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in res1[flag, "{}p"{}] <- "{}<0.001"{}: object 'res1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in rownames(res1): object 'res1' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in xtable(res1, caption = "{}Manual Version"{}): object 'res1' not found}}\end{kframe}% latex table generated in R 4.1.2 by xtable 1.8-4 package
% Tue Jan 25 13:18:00 2022
\begin{table}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{rlllll}
  \toprule
 & Est & SE & t & p & FMI \\ 
  \midrule
1 & 0.023 & 0.037 & 0.609 & 0.543 & 0.37 \\ 
  2 & 0.21 & 0.042 & 4.994 & $<$0.001 & 0.468 \\ 
  3 & 0.157 & 0.04 & 3.953 & $<$0.001 & 0.427 \\ 
   \bottomrule
\end{tabular}
}
\caption{MICE Version} 
\end{table}


\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Joint Modeling}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Definition of Regression Parameters}
  
  So far, we've been using the least-squares estimates of $\alpha$, $\beta$, and 
  $\sigma^2$ to parameterize our posterior distributions.
  \vc
  \begin{itemize}
  \item We can also define the parameters in terms of sufficient statistics.
  \end{itemize}
  \vb
  Given $\mu$ and $\Sigma$, we can define all of our regression moments as:
  \begin{align*}
    \beta &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\\
    &= \text{Cov}(\mathbf{X})^{-1} \text{Cov}(\mathbf{X}, \mathbf{Y})\\
    \alpha &= \mu_Y - \beta^T \mu_X\\
    \Sigma_{\varepsilon} &= \Sigma_Y - \beta^T \Sigma_X \beta
  \end{align*}
  These definitions are crucial for JM approaches.
  \begin{itemize}
  \item Within the subset of data define by a given response pattern, the 
    outcome variables will be entirely missing.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Multivariate Bayesian Regression}
  
  Previously, we saw examples of univariate Bayesian regression which used the 
  following model:
  \begin{align*}
    \beta &\sim \text{MVN} \left( \hat{\beta}_{ls}, ~ 
    \sigma^2 (\mathbf{X}^T \mathbf{X})^{-1} \right)\\
    \sigma^2 &\sim \text{Inv-}\chi^2 \left(N - P, MSE \right)
  \end{align*}
  We can directly extend the above to the multivariate case:
  \begin{align*}
    \Sigma^{(i)} &\sim \text{Inv-W} \left(N - 1, (N - 1) \Sigma^{(i - 1)} \right)\\
    \mu^{(i)} &\sim \text{MVN} \left(\mu^{(i - 1)}, N^{-1}\Sigma^{(i)} \right)
  \end{align*}
  We get $\alpha$, $\beta$, and $\Sigma_{\varepsilon}$ via the calculations on the 
  preceding slide
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Procedure: Joint Modeling}
  
  \begin{enumerate}
  \item Partition the incomplete data by response pattern.
    \begin{itemize}
    \item Produce $S$ subsets wherein each row shares the same response pattern.
    \end{itemize}
    \vc
  \item Provide initial guesses for $\mu$ and $\Sigma$.
    \vb
  \item Within each subset, use the current guesses of $\mu$ and $\Sigma$ to 
    generate imputations via multivariate Bayesian regression. \label{iStep}
    \vb
  \item Use the filled-in data matrix to updated the sufficient statistics.
    \label{pStep}
    \vb
  \item Repeat Steps \ref{iStep} and \ref{pStep} many times.
    \vb
  \item After the imputation model parameters have stabilized, save $M$ imputed 
    data sets produced in Step \ref{iStep}.
  \end{enumerate}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}
 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{iStep} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{pats}\hlstd{,} \hlkwc{ind}\hlstd{,} \hlkwc{p0}\hlstd{,} \hlkwc{pars}\hlstd{) \{}
    \hlcom{## Loop over non-trivial response patterns:}
    \hlkwa{for}\hlstd{(i} \hlkwa{in} \hlkwd{c}\hlstd{(}\hlnum{1} \hlopt{:} \hlkwd{nrow}\hlstd{(pats))[}\hlopt{-}\hlstd{p0]) \{}
        \hlcom{## Define the current response pattern:}
        \hlstd{p1} \hlkwb{<-} \hlstd{pats[i, ]}

        \hlcom{## Subset the data:}
        \hlstd{dat1} \hlkwb{<-} \hlstd{data[ind} \hlopt{==} \hlstd{i, ]}

        \hlcom{## Replace missing data with imputations:}
        \hlstd{data[ind} \hlopt{==} \hlstd{i,} \hlopt{!}\hlstd{p1]} \hlkwb{<-} \hlkwd{getImps}\hlstd{(}\hlkwc{data}  \hlstd{= dat1,}
                                       \hlkwc{mu}    \hlstd{= pars}\hlopt{$}\hlstd{mu,}
                                       \hlkwc{sigma} \hlstd{= pars}\hlopt{$}\hlstd{sigma,}
                                       \hlkwc{p1}    \hlstd{= p1)}
    \hlstd{\}}

    \hlcom{## Return the imputed data:}
    \hlstd{data}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{getImps} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{,} \hlkwc{mu}\hlstd{,} \hlkwc{sigma}\hlstd{,} \hlkwc{p1}\hlstd{) \{}
    \hlcom{## Partition the parameter matrices:}
    \hlstd{mY}  \hlkwb{<-} \hlkwd{matrix}\hlstd{(mu[}\hlopt{!}\hlstd{p1])}
    \hlstd{mX}  \hlkwb{<-} \hlkwd{matrix}\hlstd{(mu[p1])}
    \hlstd{sY}  \hlkwb{<-} \hlstd{sigma[}\hlopt{!}\hlstd{p1,} \hlopt{!}\hlstd{p1]}
    \hlstd{sX}  \hlkwb{<-} \hlstd{sigma[p1, p1]}
    \hlstd{cXY} \hlkwb{<-} \hlstd{sigma[p1,} \hlopt{!}\hlstd{p1]}

    \hlcom{## Compute the imputation model parameters:}
    \hlstd{beta}  \hlkwb{<-} \hlkwd{solve}\hlstd{(sX)} \hlopt{%*%} \hlstd{cXY}
    \hlstd{alpha} \hlkwb{<-} \hlstd{mY} \hlopt{-} \hlkwd{t}\hlstd{(beta)} \hlopt{%*%} \hlstd{mX}
    \hlstd{sE}    \hlkwb{<-} \hlstd{sY} \hlopt{-} \hlkwd{t}\hlstd{(beta)} \hlopt{%*%} \hlstd{sX} \hlopt{%*%} \hlstd{beta}

    \hlcom{## Pull out predictors:}
    \hlstd{X} \hlkwb{<-} \hlkwd{as.matrix}\hlstd{(data[ , p1])}

    \hlcom{## Generate and return the imputations:}
    \hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(X)}
    \hlkwd{matrix}\hlstd{(}\hlnum{1}\hlstd{, n)} \hlopt{%*%} \hlkwd{t}\hlstd{(alpha)} \hlopt{+} \hlstd{X} \hlopt{%*%} \hlstd{beta} \hlopt{+} \hlkwd{rmvnorm}\hlstd{(n,} \hlkwc{sigma} \hlstd{= sE)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pStep} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{data}\hlstd{) \{}
    \hlcom{## Update the complete-data sufficient statistics:}
    \hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(data)}
    \hlstd{m} \hlkwb{<-} \hlkwd{colMeans}\hlstd{(data)}
    \hlstd{s} \hlkwb{<-} \hlstd{(n} \hlopt{-} \hlnum{1}\hlstd{)} \hlopt{*} \hlkwd{cov}\hlstd{(data)}

    \hlcom{## Sample sigma and mu:}
    \hlstd{sigma} \hlkwb{<-} \hlkwd{riwish}\hlstd{((n} \hlopt{-} \hlnum{1}\hlstd{), s)}
    \hlstd{mu}    \hlkwb{<-} \hlkwd{rmvnorm}\hlstd{(}\hlnum{1}\hlstd{, m, (sigma} \hlopt{/} \hlstd{n))}

    \hlcom{## Return the updated parameters:}
    \hlkwd{list}\hlstd{(}\hlkwc{mu} \hlstd{= mu,} \hlkwc{sigma} \hlstd{= sigma)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

  Now that we've defined the necessary functions, do the imputation:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Some preliminaries:}
\hlstd{impData} \hlkwb{<-} \hlstd{missData}
\hlstd{nIter}   \hlkwb{<-} \hlnum{50}
\hlstd{nImps}   \hlkwb{<-} \hlnum{100}

\hlcom{## Summarize response patterns:}
\hlstd{rMat} \hlkwb{<-} \hlopt{!}\hlkwd{is.na}\hlstd{(impData)}
\hlstd{pats} \hlkwb{<-} \hlkwd{uniquecombs}\hlstd{(rMat)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in uniquecombs(rMat): could not find function "{}uniquecombs"{}}}\begin{alltt}
\hlstd{ind}  \hlkwb{<-} \hlkwd{attr}\hlstd{(pats,} \hlstr{"index"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pats' not found}}\begin{alltt}
\hlstd{p0}   \hlkwb{<-} \hlkwd{which}\hlstd{(}\hlkwd{apply}\hlstd{(pats,} \hlnum{1}\hlstd{, all))}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in apply(pats, 1, all): object 'pats' not found}}\begin{alltt}
\hlcom{## Get starting values for the parameters:}
\hlstd{pars} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{mu}    \hlstd{=} \hlkwd{colMeans}\hlstd{(impData,} \hlkwc{na.rm} \hlstd{=} \hlnum{TRUE}\hlstd{),}
             \hlkwc{sigma} \hlstd{=} \hlkwd{cov}\hlstd{(impData,} \hlkwc{use} \hlstd{=} \hlstr{"pairwise"}\hlstd{)}
             \hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Iterate over I- and P-Steps to generate imputations:}
\hlstd{impList3} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(m} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nImps) \{}
    \hlkwa{for}\hlstd{(rp} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nIter) \{}
        \hlstd{impData} \hlkwb{<-} \hlkwd{iStep}\hlstd{(}\hlkwc{data} \hlstd{= impData,}
                         \hlkwc{pats} \hlstd{= pats,}
                         \hlkwc{ind}  \hlstd{= ind,}
                         \hlkwc{p0}   \hlstd{= p0,}
                         \hlkwc{pars} \hlstd{= pars)}
        \hlstd{pars} \hlkwb{<-} \hlkwd{pStep}\hlstd{(impData)}

        \hlkwa{if}\hlstd{(rp} \hlopt{==} \hlstd{nIter) impList3[[m]]} \hlkwb{<-} \hlstd{impData}
    \hlstd{\}}
\hlstd{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in iStep(data = impData, pats = pats, ind = ind, p0 = p0, pars = pars): object 'pats' not found}}\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}
  
  Do the same type of imputation with \texttt{norm}:
  
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{missData} \hlkwb{<-} \hlkwd{as.matrix}\hlstd{(missData)}

\hlstd{meta}   \hlkwb{<-} \hlkwd{prelim.norm}\hlstd{(missData)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in prelim.norm(missData): could not find function "{}prelim.norm"{}}}\begin{alltt}
\hlstd{theta0} \hlkwb{<-} \hlkwd{em.norm}\hlstd{(meta,} \hlkwc{showits} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in em.norm(meta, showits = FALSE): could not find function "{}em.norm"{}}}\begin{alltt}
\hlkwd{rngseed}\hlstd{(}\hlnum{235711}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in rngseed(235711): could not find function "{}rngseed"{}}}\begin{alltt}
\hlstd{impList4} \hlkwb{<-} \hlkwd{list}\hlstd{()}
\hlkwa{for}\hlstd{(m} \hlkwa{in} \hlnum{1} \hlopt{:} \hlstd{nImps) \{}
    \hlstd{theta1} \hlkwb{<-} \hlkwd{da.norm}\hlstd{(}\hlkwc{s}     \hlstd{= meta,}
                      \hlkwc{start} \hlstd{= theta0,}
                      \hlkwc{steps} \hlstd{= nIter)}
    \hlstd{impList4[[m]]} \hlkwb{<-} \hlkwd{imp.norm}\hlstd{(}\hlkwc{s}     \hlstd{= meta,}
                              \hlkwc{theta} \hlstd{= theta1,}
                              \hlkwc{x}     \hlstd{= missData)}
\hlstd{\}}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in da.norm(s = meta, start = theta0, steps = nIter): could not find function "{}da.norm"{}}}\end{kframe}
\end{knitrout}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Joint Modeling}

  Analyze the multiply imputed data:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Manual implementation:}
\hlstd{fits3} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList3,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,} \hlkwc{data} \hlstd{= x)}
                \hlstd{)}
\hlstd{pool3} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits3)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in variances[[1]]: subscript out of bounds}}\begin{alltt}
\hlcom{## Imputation using norm():}
\hlstd{fits4} \hlkwb{<-} \hlkwd{lapply}\hlstd{(impList4,}
                \hlkwa{function}\hlstd{(}\hlkwc{x}\hlstd{)} \hlkwd{lm}\hlstd{(x1} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3,}
                               \hlkwc{data} \hlstd{=} \hlkwd{as.data.frame}\hlstd{(x)}
                               \hlstd{)}
                \hlstd{)}
\hlstd{pool4} \hlkwb{<-} \hlkwd{MIcombine}\hlstd{(fits4)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in variances[[1]]: subscript out of bounds}}\end{kframe}
\end{knitrout}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Example: Joint Modeling}

  Compare approaches:\\
  \vb
  
\begin{kframe}


{\ttfamily\noindent\bfseries\color{errorcolor}{Error in coef(pool3): object 'pool3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in vcov(pool3): object 'pool3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'cf3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in pt(t3, df3, lower.tail = FALSE): object 't3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in cbind(cf3, se3, t3, p3, fmi3): object 'cf3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in colnames(res3) <- c("{}Est"{}, "{}SE"{}, "{}t"{}, "{}p"{}, "{}FMI"{}): object 'res3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'res3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in res3[flag, "{}p"{}] <- "{}<0.001"{}: object 'res3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in coef(pool4): object 'pool4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in vcov(pool4): object 'pool4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'cf4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in pt(t4, df4, lower.tail = FALSE): object 't4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'pool4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in cbind(cf4, se4, t4, p4, fmi4): object 'cf4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in colnames(res4) <- c("{}Est"{}, "{}SE"{}, "{}t"{}, "{}p"{}, "{}FMI"{}): object 'res4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in eval(expr, envir, enclos): object 'res4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in res4[flag, "{}p"{}] <- "{}<0.001"{}: object 'res4' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in xtable(res3, caption = "{}Manual Version"{}): object 'res3' not found}}

{\ttfamily\noindent\bfseries\color{errorcolor}{Error in xtable(res4, caption = "{}NORM Version"{}): object 'res4' not found}}\end{kframe}

\end{frame}

%------------------------------------------------------------------------------%

\end{document}
