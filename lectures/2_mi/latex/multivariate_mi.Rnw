%%% Title:    Missing Data in R: Multivariate MI
%%% Author:   Kyle M. Lang
%%% Created:  2017-09-12
%%% Modified: 2024-01-29

\documentclass[10pt]{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{eurosym}
\usepackage{caption}

\captionsetup{labelformat = empty}

\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}
\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}

\title{Multivariate Multiple Imputation}
\subtitle{Utrecht University Winter School: Missing Data in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{}

%------------------------------------------------------------------------------%

\begin{document}

<<setup, include = FALSE, cache = FALSE>>=
set.seed(235711)

library(knitr)
library(ggplot2)
library(mice)
library(mvtnorm)
library(xtable)
library(pROC)
library(dplyr)
library(naniar)
library(LaplacesDemon)
library(mitools)
library(mgcv)
library(MCMCpack)
library(norm)

source("../../../code/supportFunctions.R")
source("../../../code/sim_missing/code/simMissingness.R")

options(width = 60)
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/multivariate_mi-",
               message = FALSE,
               warning = FALSE,
               comment = "")
knit_theme$set('edit-kwrite')
@

%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\section{Flavors of MI}

%------------------------------------------------------------------------------%

\begin{frame}{Joint Modeling vs. Fully Conditional Specification}

  When imputing with \emph{Joint Modeling} (JM) approaches, the missing data are 
  replaced by samples from the joint posterior predictive distribution.
  \vb
  \begin{itemize}
    \item To impute $X$, $Y$, and $Z$, we draw:
      \begin{align*}
        X, Y, Z \sim P(X, Y, Z | \theta)
      \end{align*}
  \end{itemize}
  \vb
  With \emph{Fully Conditional Specification} (FCS), the missing data are 
  replaced with samples from the conditional posterior predictive distribution 
  of each incomplete variable.
  \vb
  \begin{itemize}
  \item To impute $X$, $Y$, and $Z$, we draw:
    \begin{align*}
      X &\sim P(X | Y, Z, \theta_X)\\
      Y &\sim P(Y | X, Z, \theta_Y)\\
      Z &\sim P(Z | Y, X, \theta_Z)
    \end{align*}
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{JM: Strengths}
  
  When correctly implemented, JM approaches are guaranteed to produce 
  \emph{Bayesianly proper} imputations.
  \vb
  \begin{itemize}
  \item A sufficient condition for \emph{properness} is that the imputations 
    are randomly sampled from the correctly specified joint posterior predictive 
    distribution of the missing data.
    \vc
    \begin{itemize}
    \item This is the defining characteristic of JM methods.
    \end{itemize}
  \end{itemize}
  \va
  When using the correct distribution, imputations produced by JM methods will 
  be the best possible imputations.
  \begin{itemize}
  \item Unbiased parameter estimates
  \item Well-calibrated sampling variability
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{JM: Weaknesses}
  
  JM approaches don't scale well.
  \vc
  \begin{itemize}
  \item The computational burden increases with the number of incomplete 
    variables.
  \end{itemize}
  \va
  JM approaches are only applicable when the joint distribution of all 
  incomplete variables follows a known form.
  \vc
  \begin{itemize}
  \item Mixes of continuous and categorical variables are difficult to 
    accommodate.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{FCS: Strengths}
  
  FCS scales much better than JM.
  \vc
  \begin{itemize}
  \item FCS only samples from a series of univariate distributions, not large 
    joint distributions.
  \end{itemize}
  \va 
  FCS approaches can create imputations for variables that don't have a sensible 
  joint distribution.
  \vc
  \begin{itemize}
  \item FCS can easily treat mixes of continuous and categorical variables.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{FCS: Weaknesses}

  FCS will usually be slower than JM.
  \vc
  \begin{itemize}
  \item Each variable gets its own fully parameterized distribution, even if 
    that granularity is unnecessary.
  \end{itemize}
  \va
  When the incomplete variables don't have a known joint distribution, FCS 
  doesn't have theoretical support.
  \vc
  \begin{itemize}
  \item There is, however, a large degree of empirical support for the 
    tenability of the FCS approach.
  \item In practice, we usually choose FCS since real data rarely arise from a 
    known joint distribution.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{JM: Software Implementations}
  
  In R, MI via JM is available from several packages.
  \begin{itemize}
  \item \pkg{Amelia} \citep{amelia}
    \begin{itemize}
    \item Bootstrapped EM algorithm
    \end{itemize}
    \vc
  \item \pkg{norm} \citep{norm}
    \begin{itemize}
    \item Classic data augmentation.
    \end{itemize}
    \vc
  \item \pkg{mice} \citep{mice}
    \begin{itemize}
    \item Data augmentation for block updating.
    \end{itemize}
  \end{itemize}
  \vb
  JM imputation is also available in SAS, Stata, SPSS, and Mplus.
  
\end{frame}

 
%------------------------------------------------------------------------------%

\begin{frame}{FCS: Software Implementations}
  
  The \pkg{mice} package is the most popular R implementation of FCS.  
  \citep{mice}.
  \begin{itemize}
  \item Mature implementation
  \item Well integrated into the larger R ecosystem
  \item Very active development
  \end{itemize}
  \vb
  The \pkg{mi} package \citep{mi} offers another option.
  \begin{itemize}
  \item More focus on diagnostics
  \item Object oriented flavor
  \item Not very actively developed
  \end{itemize}
  \vb
  FCS imputation is also available in SAS, SPSS, Stata, and Mplus.
  
\end{frame}

%------------------------------------------------------------------------------%

\section{Procedures}

%------------------------------------------------------------------------------%

\begin{frame}{FCS: Procedure}
  
  \begin{enumerate}
  \item Fill the missing data with reasonable guesses.
    \vb
  \item For each incomplete variable, do a single iteration of univariate 
    Bayesian MI (e.g., as seen in the last set of slides). \label{eiStep}
    \vb
    \begin{itemize}
    \item After each variable on the data set is so treated, we've completed one 
      iteration.
    \end{itemize}
    \vc
  \item Repeat Step \ref{eiStep} many times.
    \vb
  \item After the imputation model parameters stabilize, save $M$ imputed data 
    sets.
  \end{enumerate}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Aside: Definition of Regression Parameters}
  
  So far, we've been using the least-squares estimates of $\alpha$, $\beta$, and 
  $\sigma^2$ to parameterize our posterior distributions.
  \vc
  \begin{itemize}
  \item We can also define the parameters in terms of sufficient statistics.
  \end{itemize}
  \vb
  Given $\mu$ and $\Sigma$, we can define all of our regression moments as:
  \begin{align*}
    \beta &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\\
    &= \text{Cov}(\mathbf{X})^{-1} \text{Cov}(\mathbf{X}, \mathbf{Y})\\
    \alpha &= \mu_Y - \beta^T \mu_X\\
    \Sigma_{\varepsilon} &= \Sigma_Y - \beta^T \Sigma_X \beta
  \end{align*}
  These definitions are crucial for JM approaches.
  \begin{itemize}
  \item Within the subset of data define by a given response pattern, the 
    outcome variables will be entirely missing.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{JM: Procedure}
  
  In JM imputation, we estimate the imputation model via the 
  \citet{tannerWong:1987} \emph{data augmentation} algorithm.
  \vc
  \begin{enumerate}
  \item Partition the incomplete data by response pattern.
    \begin{itemize}
    \item Produce $S$ subsets wherein each row shares the same response pattern.
    \end{itemize}
    \vc
  \item Provide initial guesses for $\mu$ and $\Sigma$.
    \vb
  \item Within each subset, use the current guesses of $\mu$ and $\Sigma$ to 
    generate imputations via multivariate Bayesian regression. \label{iStep}
    \vb
  \item Use the filled-in data matrix to updated the sufficient statistics.
    \label{pStep}
    \vb
  \item Repeat Steps \ref{iStep} and \ref{pStep} many times.
    \vb
  \item After the imputation model parameters have stabilized, save $M$ imputed 
    data sets produced in Step \ref{iStep}.
  \end{enumerate}
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{JM: Visualing Patternwise Estimation}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      \begin{align*}
        \beta &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{Y}\\
        &= \text{Cov}(\mathbf{X})^{-1} \text{Cov}(\mathbf{X}, \mathbf{Y})\\
        \alpha &= \mu_Y - \beta^T \mu_X\\
        \Sigma_{\varepsilon} &= \Sigma_Y - \beta^T \Sigma_X \beta
      \end{align*}
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE>>=
      simData <- simCovData(nObs = 1000, sigma = 0.25, nVars = 4)
  
      missData <- imposeMissData(data    = simData,
                                 targets = paste0("x", 1:3),
                                 preds   = "x4",
                                 pm      = 0.3,
                                 types = c("low", "center", "high")
                                 )
      ggmice::plot_pattern(missData)
      @         
      
    \end{column}
  \end{columns}
    
\end{frame}

%------------------------------------------------------------------------------%

\section{Mixed Data Types}

%------------------------------------------------------------------------------%

\begin{frame}{FCS for Mixed Data Types}

  FCS imputation can easily accommodate incomplete data that contain both 
  continuous and categorical/non-normal variables.
  \vc
  \begin{itemize}
  \item Replace the normal-theory elementary imputation model described above 
    with an appropriate model for the distribution of each incomplete variable
    \vc
    \begin{itemize}
    \item Logistic regression (various flavors)
      \vc
    \item Donor-based methods
      \vc
    \item Tree-based methods
    \end{itemize}
  \end{itemize}
  \vb
  The FCS framework can essentially accommodate any data for which you can define 
  an appropriate supervised model.
  \vc
  \begin{itemize}
  \item Many useful methods are already implemented in the \pkg{mice} package.
  \end{itemize}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{JM for Mixed Data Types}

  When applying JM to incomplete data with mixed variable types, we have to 
  general options.
  \vc
  \begin{enumerate}
  \item Impute under the multivariate normal model and round, coarsen, or 
    truncate the continuous imputations to ``match'' the original data.
    \vc
    \begin{itemize}
    \item This was the old-school recommendation from the days before FCS 
      \citep[e.g.,][]{allison:2002, schafer:1997}.
      \vc
    \item The \pkg{Amelia} package implements this approach.
      \vc
    \item This approach tends to perform poorly in methodological evaluations 
      \citep[e.g.,][]{langWu:2017,wuEtAl:2015}.
    \end{itemize}
    \vb
  \item Impute under an appropriate joint model for the data.
    \vc
    \begin{itemize}
    \item This approach is only available when a suitable joint model exists.
      \vc
    \item The \pkg{mix} package \citep{mix} implements this approach for the 
      general location model \citep{littleSchluchter:1985}.
      \vc
    \item This approach also doesn't do very well, in practice \citep{langWu:2017}.
    \end{itemize}
  \end{enumerate}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{References}
  
  \bibliographystyle{apacite}
  \bibliography{../../../bibtex/winter_school_refs.bib}
  
\end{frame}

%------------------------------------------------------------------------------%

\end{document}



%------------------------------------------------------------------------------%
%------------------------------------------------------------------------------%
%------------------------------------------------------------------------------%



\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example: Data Generation}
  
  First we'll simulate some synthetic data.
  
  <<>>=
  ## Simulate some data:
  simData <- 
      simCovData(nObs = 1000, sigma = 0.25, nVars = 4)
  
  head(simData, 10)
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Data Generation}

  Next, we impose some missing values on the simulated data.
  
  <<>>=
  targets  <- paste0("x", 1:3)
  missData <- imposeMissData(data    = simData,
                             targets = targets,
                             preds   = "x4",
                             pm      = 0.3,
                             types = c("low", "center", "high")
                             )
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Data Visualization}

  Check the results.
  
<<>>=
head(missData, 10)
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example: Data Visualization}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      
      Use the \code{naniar::vis\_missing()} function to visualize the pattern of 
      missing values.
      
      <<eval = FALSE>>=
      vis_miss(missData)
      @ 
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE>>=
      vis_miss(missData)
      @ 
      
    \end{column}
  \end{columns}
  
\end{frame}


