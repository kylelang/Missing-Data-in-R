%%% Title:    Missing Data in R: Manual FIML Example
%%% Author:   Kyle M. Lang
%%% Created:  2015-09-29
%%% Modified: 2023-01-29

\documentclass[10pt]{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{eurosym}
\usepackage{caption}
\usepackage[mathcal]{eucal}
\usepackage{upgreek}

\captionsetup{labelformat = empty}

\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}
\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\mub}[0]{\boldsymbol{\muup}}

\title{ML \& FIML Example}
\subtitle{Utrecht University Winter School: Missing Data in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{}

%------------------------------------------------------------------------------%

\begin{document}

<<knitr_setup, include = FALSE, cache = FALSE>>=
options(width = 60)
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/fiml_example-",
               message = FALSE,
               warning = FALSE,
               comment = "")
opts_knit$set(root.dir = "../../../")
knit_theme$set('edit-kwrite')
@

<<r_setup, include = FALSE, cache = FALSE>>=
set.seed(235711)

library(knitr)
library(ggplot2)
library(mice)
library(mvtnorm)
library(xtable)
library(pROC)
library(dplyr)
library(mgcv)
library(optimx)
library(lavaan)

source("code/supportFunctions.R")
source("code/sim_missing/code/simMissingness.R")

dataDir <- "data/"
@

%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Maximum Likelihood}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{ML Example}
  
  Recall the $n$th observation's contribution to the multivariate normal 
  loglikelihood function:
  \begin{align*}
    \mathcal{L} \left( \mub, \Sigma \right)_n = 
    -\frac{P}{2} \ln(2\pi) - \frac{1}{2} \ln |\Sigma| - \frac{1}{2} (\mathbf{Y}_n - \mub)^T \Sigma^{-1}(\mathbf{Y}_n - \mub).
  \end{align*}

  \va

  It turns out that this function is readily available in R via the 
  \textbf{mvtnorm} package:

  <<eval = FALSE>>=
  ## Vector of row-wise contributions to the overall LL:
  ll0 <- dmvnorm(y, mean = mu, sigma = sigma, log = TRUE)
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{ML Example}

  We can wrap the preceding code in a nice R function:

  <<>>=
  ## Complete data loglikelihood function:
  ll <- function(par, data) {
      ## Extract the parameter matrices:
      p  <- ncol(data)
      mu <- par[1:p]
      
      ## Populate sigma from its Cholesky factor:
      sigma <- vecChol(tail(par, -p), p = p, revert = TRUE)
      
      ## Compute the row-wise contributions to the LL:
      ll0 <- dmvnorm(data, mean = mu, sigma = sigma, log = TRUE)
      
      sum(ll0)# return the overall LL value
  }
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{ML Example}

  We'll also need the following helper function:
  
  <<>>=
  ## Convert from covariance matrix to vectorized Cholesky factor and back:
  vecChol <- function(x, p, revert = FALSE) {
      if(revert) {
          tmp                  <- matrix(0, p, p)
          tmp[!lower.tri(tmp)] <- x
          crossprod(tmp)
      }
      else
          chol(x)[!lower.tri(x)]
  }
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{ML Example}
  
  The \textbf{optimx} package can numerically optimize arbitrary functions.
  \begin{itemize}
  \item We can use it to (semi)manually implement ML.
  \end{itemize}
  
  <<>>=
  ## Subset the 'diabetes' data:
  dat1 <- readRDS(paste0(dataDir, "diabetes.rds")) %>%
      select(bmi, ldl, glu) %>%
      as.matrix()

  ## Choose some starting values:
  m0   <- rep(0, 3)
  s0   <- diag(3) %>% vecChol()
  par0 <- c(m0, s0)

  ## Use optimx() to numerically optimize the LL function:
  mle <- optimx(par     = par0,
                fn      = ll,
                data    = dat1,
                method  = "BFGS",
                control = list(maximize = TRUE, maxit = 1000)
                )
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{ML Example}
  
  Finally, let's check convergence and extract the optimized parameters:
  
  <<>>=
  ## Check convergence:
  mle[c("convcode", "kkt1", "kkt2")]

  ## Get the optimize mean vector and covariance matrix:
  muHat    <- mle[1:3]
  sigmaHat <- mle[4:9] %>% as.numeric() %>% vecChol(p = 3, revert = TRUE)
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{ML Example}
  
  <<echo = FALSE, results = "asis">>=
  names(muHat) <- colnames(dat1)

  muMat           <- rbind(muHat, colMeans(dat1))
  rownames(muMat) <- c("ML", "Closed Form")

  print(xtable(muMat, digits = 3, caption = "Estimated Means"), booktabs = TRUE)
  @ 
  
  \vx{-12}

  \begin{columns}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, results = "asis">>= 
      colnames(sigmaHat) <- rownames(sigmaHat) <- colnames(dat1)
      print(xtable(sigmaHat, digits = 3, caption = "ML Covariance Matrix"), 
            booktabs = TRUE)
      @ 
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, results = "asis">>= 
      print(xtable(cov(dat1), digits = 3, caption = "Closed Form Covariance Matrix"), 
            booktabs = TRUE)
      @
      
    \end{column}
  \end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Full Information Maximum Likelihood}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}

  First things first, we need to punch some holes in our example data.
  
  <<>>=
  ## Impose MAR missing:
  dat2 <- imposeMissData(data    = dat1,
                         targets = c("ldl", "glu"),
                         preds   = "bmi",
                         pm      = 0.3,
                         types   = c("low", "high"),
                         stdDat  = TRUE)
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Visualize the Response Patterns}
  
  <<echo = FALSE>>=
  nPats <- mice::md.pattern(dat2, plot = FALSE) %>% nrow() - 1
  @
  
  \begin{columns}
    \begin{column}{0.5\textwidth}
      
      The data contain \Sexpr{nPats} unique response patterns.
      \vc
      \begin{itemize}
      \item We'll define \Sexpr{nPats} different version of $\mu$ and $\Sigma$.
        \vc
      \item We'll calculate each individual loglikelihood contributions using 
        the appropriate flavor of $\mu$ and $\Sigma$. 
      \end{itemize}
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE>>=
      ggmice::plot_pattern(dat2)
      @
      
    \end{column}
  \end{columns}
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}

  <<>>=
  ## Compute the within-pattern contributions to the LL:
  ll0 <- function(i, mu, sigma, pats, ind, data) {
      ## Define the current response pattern:
      p1 <- pats[i, ]
      
      if(sum(p1) > 1) # More than one observed variable?
          dmvnorm(x     = data[ind == i, p1],
                  mean  = mu[p1],
                  sigma = sigma[p1, p1],
                  log   = TRUE)
      else
          dnorm(x    = data[ind == i, p1],
                mean = mu[p1],
                sd   = sqrt(sigma[p1, p1]),
                log  = TRUE)
  }
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}

  <<>>=
  ## FIML loglikelihood function:
  llm <- function(par, data, pats, ind) {
      ## Extract the parameter matrices:
      p  <- ncol(data)
      mu <- par[1:p]
      
      ## Populate sigma from its Cholesky factor:
      sigma <- vecChol(tail(par, -p), p = p, revert = TRUE)
      
      ## Compute the pattern-wise contributions to the LL:
      ll1 <- sapply(X     = 1:nrow(pats),
                    FUN   = ll0,
                    mu    = mu,
                    sigma = sigma,
                    pats  = pats,
                    ind   = ind,
                    data  = data)
      
      sum(unlist(ll1))
  }
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}

  <<>>=
  ## Summarize response patterns:
  pats <- uniquecombs(!is.na(dat2))
  ind  <- attr(pats, "index")
  
  ## Choose some starting values:
  m0   <- colMeans(dat2, na.rm = TRUE)
  s0   <- cov(dat2, use = "pairwise") %>% vecChol()
  par0 <- c(m0, s0)
  
  ## Use optimx() to numerically optimize the LL function:
  mle <- optimx(par     = par0,
                fn      = llm,
                data    = dat2,
                pats    = pats,
                ind     = ind,
                method  = "BFGS",
                control = list(maximize = TRUE, maxit = 1000)
                )
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}
  
  Check convergence and extract the optimized parameters:
  
  <<>>=
  ## Check convergence:
  mle[c("convcode", "kkt1", "kkt2")]
  
  ## Get the optimize mean vector and covariance matrix:
  muHat1    <- mle[1:3]
  sigmaHat1 <- mle[4:9] %>% as.numeric() %>% vecChol(p = 3, revert = TRUE)
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{FIML Example}

  Just to make sure our results are plausible, we can do the same analysis using 
  the \code{cfa()} function from the \textbf{lavaan} package:

  <<>>=
  ## Define the model in lavaan syntax:
  mod <- "
  bmi ~~ ldl + glu
  ldl ~~ glu
  "
  
  ## Fit the model with lavaan::cfa():
  fit <- cfa(mod, data = dat2, missing = "fiml")
  
  ## Extract the estimated parameters:
  muHat2    <- inspect(fit, "est")$nu
  sigmaHat2 <- inspect(fit, "theta")
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{FIML Example}
  
  <<echo = FALSE, results = "asis">>=
  muMat           <- rbind(muHat1, t(muHat2))
  colnames(muMat) <- colnames(dat1)
  rownames(muMat) <- c("Manual", "Lavaan")
  
  print(xtable(muMat, digits = 3, caption = "Estimated Means"), booktabs = TRUE)
  @ 
  
  \vx{-12}
  
  \begin{columns}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, results = "asis">>= 
      colnames(sigmaHat1) <- rownames(sigmaHat1) <- colnames(dat1)
      print(xtable(sigmaHat1, 
                   digits  = 3, 
                   caption = "Manual FIML Covariance Matrix"), 
            booktabs = TRUE)
      @ 
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, results = "asis">>= 
      print(xtable(sigmaHat2, 
                   digits  = 3, 
                   caption = "Lavaan FIML Covariance Matrix"), 
            booktabs = TRUE)
      @
    
    \end{column}
  \end{columns}
  
\end{frame}

%------------------------------------------------------------------------------%

\end{document}
