%%% Title:    Missing Data in R: Introduction
%%% Author:   Kyle M. Lang
%%% Created:  2015-11-06
%%% Modified: 2023-01-27

\documentclass{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{eurosym}
\usepackage{caption}

\captionsetup{labelformat = empty}

\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}


\title{Missing Data Basics}
\subtitle{Utrecht University Winter School: Missing Data in R}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{}

%------------------------------------------------------------------------------%

\begin{document}

<<knitr_setup, include = FALSE, cache = FALSE>>=
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/intro-",
               message = FALSE,
               warning = FALSE,
               comment = "")
opts_knit$set(root.dir = "../../../")
knit_theme$set('edit-kwrite')
@

<<r_setup, inclcude = FALSE>>=
options(width = 60)

set.seed(235711)

library(knitr)
library(ggplot2)
library(mice)
library(mvtnorm)
library(xtable)
library(pROC)
library(dplyr)
library(magrittr)
library(naniar)
library(ggpubr)
library(lme4)
library(lavaan)

dataDir <- "data/"

source("code/supportFunctions.R")
source("code/sim_missing/code/simMissingness.R")
@

%------------------------------------------------------------------------------%

\begin{frame}[t, plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{What are Missing Data?}

  Missing data are empty cells in a dataset where there should be observed
  values.
  \vc
  \begin{itemize}
  \item The missing cells correspond to true population values, but we haven't
    observed those values.
  \end{itemize}
  \vb
  \pause
  Not every empty cell is a missing datum.
  \vc
  \begin{itemize}
  \item Quality-of-life ratings for dead patients in a mortality study
    \vc
  \item Firm profitability after the company goes out of business
    \vc
  \item Self-reported severity of menstrual cramping for men
    \vc
  \item Empty blocks of data following ``gateway'' items
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{A Little Notation}
  \vx{-18}
  \begin{align*}
    Y &\coloneqq \text{An $N \times P$ Matrix of Arbitrary Data}\\[8pt]
    Y_{mis} &\coloneqq \text{The \emph{missing} part of $Y$}\\[8pt]
    Y_{obs} &\coloneqq \text{The \emph{observed} part of $Y$}\\[8pt]
    R &\coloneqq \text{An $N \times P$ response matrix}\\[8pt]
    M &\coloneqq \text{An $N \times P$ missingness matrix}
  \end{align*}

  The $R$ and $M$ matrices are complementary.
  \begin{itemize}
  \item $r_{np} = 1$ means $y_{np}$ is observed; $m_{np} = 1$ means $y_{np}$ is
    missing.
  \item $r_{np} = 0$ means $y_{np}$ is missing; $m_{np} = 0$ means $y_{np}$ is
    observed.
  \item $M_p$ is the \emph{missingness} of $Y_p$.
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Missing Data Descriptives}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Missing Data Pattern}

  <<echo = FALSE>>=
  tmpTab <- matrix(c("x", "x", ".", ".",
                     "y", ".", "y", "."),
                   ncol = 2,
                   dimnames = list(NULL, c("X", "Y"))
                   )
  
  patTab1 <-
      xtable(tmpTab, align = rep("c", 3), caption = "Patterns for $P = 2$")
  
  tmpTab <- matrix(c(rep("x", 3), ".", "x", rep(".", 3),
                     "y", "y", ".", "y", ".", ".", "y", ".",
                     "z", ".", "z", "z", ".", "z", ".", "."),
                   ncol = 3,
                   dimnames = list(NULL, c("X", "Y", "Z"))
                   )
  
  patTab2 <-
      xtable(tmpTab, align = rep("c", 4), caption = "Patterns for $P = 3$")
  @
  
  Missing data (or response) patterns represent unique combinations of observed
  and missing items.
  \begin{itemize}
  \item $P$ items $\Rightarrow$ $2^P$ possible patterns.
  \end{itemize}
  
  \begin{columns}
    \begin{column}{0.45\textwidth}
      
      <<echo = FALSE, results = 'asis'>>=
      print(patTab1, booktabs = TRUE)
      @
      
    \end{column}
    \begin{column}{0.45\textwidth}
      \vx{-12}
      <<echo = FALSE, results = 'asis'>>=
      print(patTab2, booktabs = TRUE)
      @
      
    \end{column}
  \end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Missing Data Pattern}

 The concept of a ``missing data pattern'' can also be used to classify the
  spatial arrangement of missing cells on a data set.\\

  \vc

  \begin{itemize}
  \item Univariate
    \begin{itemize}
      \item Missing data occur on only one variable
    \end{itemize}

    \vb

  \item Monotone
    \begin{itemize}
    \item The proportion of complete elements, in both rows and columns,
      decreases when traversing the data set.
    \item The observed cells can be arranged into a ``staircase'' pattern.
    \end{itemize}

    \vb

  \item Arbitrary
    \begin{itemize}
    \item Missing values are ``randomly'' scattered throughout the data set.
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{Example Missing Data Patterns}

  <<echo = FALSE>>=
  tmpTab <- matrix(c(rep("x", 10),
                     rep("y", 5), rep(".", 5),
                     rep("z", 10)),
                   ncol = 3)
  colnames(tmpTab) <- c("X", "Y", "Z")
  
  patTab1 <- xtable(tmpTab,
                    align   = rep("c", 4),
                    caption = "Univariate Pattern")
  
  tmpTab2 <- matrix(c(rep("x", 9), rep(".", 1),
                      rep("y", 6), rep(".", 4),
                      rep("z", 3), rep(".", 7)),
                    ncol = 3)
  colnames(tmpTab2) <- c("X", "Y", "Z")
  
  patTab2 <- xtable(tmpTab2,
                    align   = rep("c", 4),
                    caption = "Monotone Pattern")
  
  tmpTab3 <- matrix(c(rep("x", 10),
                      rep("y", 10),
                      rep("z", 10)),
                    ncol = 3)
  rMat <- matrix(as.logical(rbinom(30, 1, 0.3)), ncol = 3)
  tmpTab3[rMat] <- "."
  colnames(tmpTab3) <- c("X", "Y", "Z")
  
  patTab3 <- xtable(tmpTab3,
                    align   = rep("c", 4),
                    caption = "Arbitrary Pattern")
  @
  
  \begin{columns}[T]
    \begin{column}{0.33\textwidth}
      
      <<echo = FALSE, results = 'asis'>>=
      print(patTab1, booktabs = TRUE)
      @
      
    \end{column}
    \begin{column}{0.33\textwidth}
      
      <<echo = FALSE, results = 'asis'>>=
      print(patTab2, booktabs = TRUE)
      @
      
    \end{column}
    \begin{column}{0.33\textwidth}
      
      <<echo = FALSE, results = 'asis'>>=
      print(patTab3, booktabs = TRUE)
      @
      
    \end{column}
  \end{columns}
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Nonresponse Rates}

  \rmsc{Proportion Missing}
  %\begin{align*}
  %  PM_p = N^{-1} \sum_{n = 1}^N r_{np}
  %\end{align*}
  \begin{itemize}
  \item The proportion of cells containing missing data
  \item Good early screening measure
  \item Should be computed for each variable, not for the entire dataset
  \end{itemize}

  \va

  \rmsc{Attrition Rate}
  \begin{itemize}
  \item The proportion of participants that drop-out of a study at each
    measurement occasion
  \end{itemize}

  \pagebreak

  \rmsc{Proportion of Complete Cases}
  \begin{itemize}
  \item The proportion of observations with no missing data
  \item Often reported but nearly useless quantity
  \end{itemize}

  \va

  \rmsc{Fraction of Missing Information}
  \begin{itemize}
  \item Associated with an estimated parameter, not with an incomplete variable
  \item Like an $R^2$ for the missing data
  \item Most important diagnostic value for missing data problems
  \item Can only be computed after treating the missing data
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Coverage Measures}

  \rmsc{Covariance Coverage}
  \begin{align*}
    CC_{jk} = N^{-1} \sum_{n = 1}^N r_{nj}r_{nk}
  \end{align*}
  \begin{itemize}
  \item The proportion of cases available to estimate a given pairwise
    relationship (e.g., a covariance between two variables)
  \item Very important to have adequate coverage of the parameters you
    want to estimate
  \end{itemize}

  \pagebreak

  \rmsc{Inbound Statistic}
  \begin{align*}
    I_{jk} = \frac{\sum_{n = 1}^N (1 - r_{nj})r_{nk}}{\sum_{n = 1}^N (1 - r_{nj})}
  \end{align*}
  \begin{itemize}
  \item The proportion of missing cases in $Y_{j}$ for which $Y_{k}$ is observed
  \end{itemize}

  \va

  \rmsc{Outbound Statistic}
  \begin{align*}
    O_{jk} = \frac{\sum_{n = 1}^N r_{nj}(1 - r_{nk})}{\sum_{n = 1}^N r_{nj}}
  \end{align*}
  \begin{itemize}
  \item The proportion of observed cases in $Y_{j}$ for which $Y_{k}$ is missing
  \end{itemize}

  \pagebreak

  \rmsc{Influx Coefficient}
  \begin{align*}
    I_j = \frac{\sum_{k = 1}^P \sum_{n = 1}^N (1 - r_{nj})r_{nk}}{\sum_{k = 1}^P \sum_{n = 1}^N r_{nk}}
  \end{align*}
  \begin{itemize}
  \item The proportion of observed cells in $Y$ that exists in cases for which
    $Y_j$ is missing
  \item How well the missing values in $Y_j$ connect to the observed values in
    $Y_{-j}$
  \end{itemize}

  \pagebreak

  \rmsc{Outflux Coefficient}
  \begin{align*}
    O_j = \frac{\sum_{k = 1}^P \sum_{n = 1}^N r_{nj}(1 - r_{nk})}{\sum_{k = 1}^P \sum_{n = 1}^N (1 - r_{nk})}
  \end{align*}
  \begin{itemize}
  \item The proportion of missing cells in $Y$ that exists in cases for which
    $Y_j$ is observed
  \item How well the observed values in $Y_j$ connect to the missing values in
    $Y_{-j}$
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Missing Data Mechanisms}

%------------------------------------------------------------------------------%

\begin{frame}{Missing Data Mechanisms}

  Missing Completely at Random (MCAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) = P(R)$
    \vc
  \item Missingness is unrelated to any study variables.
  \end{itemize}
  \vb
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) = P(R)
  %\end{align*}

  Missing at Random (MAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) = P(R | Y_{obs})$
    \vc
  \item Missingness is related to only the \emph{observed} parts of study
      variables.
  \end{itemize}
  \vb
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) = P(R | Y_{obs})
  %\end{align*}

  Missing not at Random (MNAR)
  \begin{itemize}
  \item $P(R | Y_{mis}, Y_{obs}) \neq P(R | Y_{obs})$
    \vc
  \item Missingness is related to the \emph{unobserved} parts of study
    variables.
  \end{itemize}
  %\begin{align*}
  %  P(R | Y_{mis}, Y_{obs}) \neq P(R | Y_{obs})
  %\end{align*}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Simulate Some Toy Data}

  <<>>=
  library(mvtnorm)
  library(dplyr)
  library(magrittr)
  
  nObs <- 5000 # Sample Size
  pm   <- 0.3  # Proportion Missing
  
  sigma <- matrix(c(1.0, 0.5, 0.3,
                    0.5, 1.0, 0.0,
                    0.3, 0.0, 1.0),
                  ncol = 3)
  dat0 <- rmvnorm(nObs, c(0, 0, 0), sigma) %>% data.frame()
  colnames(dat0) <- c("x", "y", "z")
  
  dat0 %$% cor(y, x)
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MCAR Example}
  
  <<>>=
  ## Simulate MCAR Missingness:
  m <- sample(1:nObs, size = pm * nObs)

  ## Impose MCAR missing on Y:
  mcarData         <- dat0
  mcarData[m, "y"] <- NA

  ## Check the correlation between X & Y:
  mcarData %$% cor(y, x, use = "pairwise")
  @
  
  \pagebreak
  
  <<echo = FALSE, out.width = "65%">>=
  y0Den <- dat0 %$% density(y)
  yDen  <- mcarData %$% density(y, na.rm = TRUE)
  
  pDat <- data.frame(y = c(y0Den$y, yDen$y),
                     x = c(y0Den$x, yDen$x),
                     g = rep(c("Complete", "MCAR w/ Deletion"),
                             each = length(yDen$y)
                             )
                     )
  
  ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
      geom_line(size = 1) +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      ylab("Density") +
      xlab("Value of Y") +
      scale_color_manual(values = c("blue", "red")) +
      theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MAR Example}

  <<>>=
  ## Simulate MAR Missingness:
  m <- with(dat0, x < quantile(x, probs = pm))
  
  ## Impose MAR missing on Y:
  marData         <- dat0
  marData[m, "y"] <- NA
  
  ## Check the correlation between X & Y:
  marData %$% cor(y, x, use = "pairwise")
  @
  
  \pagebreak
  
  <<echo = FALSE, out.width = "65%">>=
  yDen <- marData %$% density(y, na.rm = TRUE)
  
  pDat <- data.frame(y = c(y0Den$y, yDen$y),
                     x = c(y0Den$x, yDen$x),
                     g = rep(c("Complete", "MAR w/ Deletion"),
                             each = length(yDen$y)
                             )
                     )
  
  marP <- ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
      geom_line(size = 1) +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      ylab("Density") +
      xlab("Value of Y") +
      scale_color_manual(values = c("blue", "red")) +
      theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
  marP
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{MNAR Example}

  <<>>=
  ## Simulate MNAR Missingness:
  m <- with(dat0, y < quantile(y, probs = pm))

  ## Impose MNAR missing on Y:
  mnarData         <- dat0
  mnarData[m, "y"] <- NA

  ## Check the correlation between X & Y:
  mnarData %$% cor(y, x, use = "pairwise")
  @
  
  \pagebreak
  
  <<echo = FALSE, out.width = "65%">>=
  yDen <- mnarData %$% density(y, na.rm = TRUE)
  
  pDat <- data.frame(y = c(y0Den$y, yDen$y),
                     x = c(y0Den$x, yDen$x),
                     g = rep(c("Complete", "MNAR w/ Deletion"),
                             each = length(yDen$y)
                             )
                     )
  
  ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
      geom_line(size = 1) +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      ylab("Density") +
      xlab("Value of Y") +
      scale_color_manual(values = c("blue", "red")) +
      theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Crucial Nuance}

  In our previous MAR example, ignoring the predictor of missingness actually
  produces \emph{Indirect MNAR}.\\

  \pause
  \va

  \rmsc{Question:} What happens if we ignore the predictor of missingness, but
  that predictor is independent of our study variables?

  \pause

  <<>>=
  m <- with(dat0, z < quantile(z, probs = pm))
  
  mcarData2         <- dat0
  mcarData2[m, "y"] <- NA
  
  mcarData2 %$% cor(y, x, use = "pairwise")
  @
  
  \rmsc{Answer:} We get back to MCAR :)
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Crucial Nuance}
  
  The missing data mechanisms are not simply characteristics of an incomplete
  dataset; we also need to account for the analysis.
  \vb
  \begin{columns}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, out.width = "100%", message = FALSE>>=
      marP + scale_color_manual(values = c("blue", "red"),
                                labels = c("Complete", "Indirect MNAR")
                                )
      @
      
    \end{column}
    \begin{column}{0.5\textwidth}
      
      <<echo = FALSE, out.width = "100%">>=
      yDen <- mcarData2 %$% density(y, na.rm = TRUE)
      
      pDat <- data.frame(y = c(y0Den$y, yDen$y),
                         x = c(y0Den$x, yDen$x),
                         g = rep(c("Complete", "MCAR2"),
                                 each = length(yDen$y)
                                 )
                         )
      
      ggplot(data = pDat, mapping = aes(x = x, y = y, color = g)) +
          geom_line(size = 1) +
          theme_classic() +
          theme(text = element_text(family = "Courier", size = 16)) +
          ylab("Density") +
          xlab("Value of Y") +
          scale_color_manual(values = c("blue", "red")) +
          theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
      @
      
    \end{column}
  \end{columns}
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Testing the Missing Data Mechanism}

  We cannot fully test the MAR or MNAR assumptions.
  \begin{itemize}
  \item To do so would require knowing the values of the missing data.
    \vc
  \item We can find observed predictors of missingness.
    \begin{itemize}
    \item Use classification algorithms to predict missingness from $Y_{obs}$.
      \vc
    \item We can never know that we have discovered all MAR predictors.
    \end{itemize}
    \vc
  \item In practice, MAR and MNAR live on the ends of a continuum.
    \begin{itemize}
    \item Our missing data problem exists at some unknown point along this
      continuum.
      \vc
    \item We can do a lot to nudge our problem towards the MAR side.
    \end{itemize}
  \end{itemize}

  \pagebreak

  We can (partially) test the MCAR assumption.
  \begin{itemize}
  \item With MCAR, the missing data and the observed data should have the same
    distribution.
    \vc
  \item We can test for MCAR by testing the distributions of \emph{auxiliary
    variables}, $\mathbf{Z}$.
    \begin{itemize}
    \item Use a t-test to compare the subset of $Z_p$ that corresponds to
      $Y_{mis}$ to the subset corresponding to $Y_{obs}$.
      \vc
    \item The \citet{little:1988_mcar} MCAR test is a multivariate version of this.
    \end{itemize}
  \end{itemize}
  \vc
  These procedures actually test if the data are \emph{observed} completely at
  random.

\end{frame}

%------------------------------------------------------------------------------%

\sectionslide{Missing Data Treatments}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Bad Methods (These almost never work)}

  Listwise Deletion (Complete Case Analysis)
  \begin{itemize}
  \item Use only complete observations for the analysis
    \begin{itemize}
    \item Very wasteful (can throw out lots of useful data)
    \item Loss of statistical power
    \end{itemize}
  \end{itemize}

  \vb

  Pairwise Deletion (Available Case Analysis)
  \begin{itemize}
  \item Use only complete pairs of observations for analysis
    \begin{itemize}
    \item Different samples sizes for different parameter estimates
    \item Can cause computational issues
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  ## Read in some data:
  tmp <- readRDS(paste0(dataDir, "diabetes.rds")) %>%
      select(bmi, bp, glu, age)
  diabetes1 <- diabetes2 <-
      rmvnorm(500, colMeans(tmp), cov(tmp)) %>% data.frame()

  ## Simulated missingness based on 'bmi':
  m <- simLinearMissingness(data  = diabetes2,
                            pm    = 0.30,
                            preds = "bmi",
                            auc   = 0.85)$r
  
  ## Impose missing on 'glu' according to the missingess above:
  diabetes2[m, "glu"] <- NA
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
  <<echo = FALSE, cache = TRUE, fig.asp = 0.55>>=
  diabetes1$Response <- factor(m, labels = c("Observed", "Missing"))
  
  p0 <- ggplot(data = diabetes1, mapping = aes(x = bmi, y = glu)) +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      xlab("BMI") +
      ylab("Blood Glucose")
  
  ggarrange(
      p0 + 
      geom_point(size = 0.75) + 
      ggtitle("Fully Observed Data") +
      theme(text = element_text(size = 8),
            axis.title = element_blank(),
            plot.title = element_text(face = "bold", hjust = 0.5)
            ),
      
      p0 + 
      geom_point(aes(color = Response), size = 0.75) + 
      scale_color_manual(values = c("black", "gray")) +
      ggtitle("Incomplete Data") +
      theme(text = element_text(size = 8),
            axis.title = element_blank(),
            axis.text.y = element_blank(),
            plot.title = element_text(face = "bold", hjust = 0.5),
            legend.position = "none"),
      
      ncol = 2,
      widths = c(1.05, 1)
  ) %>%
      annotate_figure(left = text_grob("Blood Glucose", 
                                       family = "Courier", 
                                       size = 10,
                                       rot = 90),
                      bottom = text_grob("BMI", family = "Courier", size = 10)
                      )
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  diabetes2 %>% select(bmi, glu, bp) %>% cor(use = "complete")
  @ 
  
\end{frame}

%------------------------------------------------------------------------------

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  diabetes2 %>% select(bmi, glu, bp) %>% cor(use = "pairwise")
  @ 

\end{frame}

%------------------------------------------------------------------------------

\begin{frame}[fragile]{Example}

  <<>>=
  mean(diabetes1$glu)
  mean(diabetes2$glu, na.rm = TRUE)
  var(diabetes1$glu)
  var(diabetes2$glu, na.rm = TRUE)
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
  s2 <- lm(glu ~ bmi + bp + age, data = diabetes2) %>% summary()
  
  s1$r.squared
  s2$r.squared
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1$coef
  s2$coef
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      (Unconditional) Mean Substitution
      \begin{itemize}
      \item Replace $Y_{mis}$ with $\bar{Y}_{obs}$
        \begin{itemize}
        \item Negatively biases regression slopes and correlations
        \item Attenuates measures of linear association
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{
        
        <<echo = FALSE, cache = TRUE>>=
        p1 <- p0 + 
            geom_point(aes(color = Response)) + 
            scale_color_manual(values = c("black", "gray")) +
            theme(legend.position = "none")
        
        p1
        @
        
      }
      \only<2>{
        
        <<echo = FALSE, cache = TRUE>>=
        miceM <- mice(data      = diabetes2[ , c("bmi", "glu")],
                      m         = 1,
                      maxit     = 1,
                      method    = "mean",
                      printFlag = FALSE)
        
        datM0 <- datM <- complete(miceM, 1)
        datM[!m, ] <- NA
        
        p2 <- p1 + geom_point(data    = datM,
                              mapping = aes(y = glu, x = bmi),
                              colour  = "red")
        p2
        @
        
      }
      
      \only<3>{
        
        <<echo = FALSE, cache = TRUE>>=
        p2 + geom_smooth(data    = diabetes1,
                         mapping = aes(y = glu, x = bmi),
                         method  = "lm",
                         color   = "blue",
                         se      = FALSE) +
            geom_smooth(data    = datM0,
                        mapping = aes(y = glu, x = bmi),
                        method  = "lm",
                        color   = "red",
                        se      = FALSE)
        @
        
      }
      
    \end{column}
  \end{columns}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
  
  <<>>=
  imputed <- diabetes2
  imputed[m, "glu"] <- mean(imputed$glu, na.rm = TRUE)
  
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  imputed %>% select(bmi, glu, bp) %>% cor()
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  mean(diabetes1$glu)
  mean(imputed$glu, na.rm = TRUE)
  var(diabetes1$glu)
  var(imputed$glu, na.rm = TRUE)
  @ 
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
  s2 <- lm(glu ~ bmi + bp + age, data = imputed) %>% summary()
  
  s1$r.squared
  s2$r.squared
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1$coef
  s2$coef
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      Deterministic Regression Imputation\\
      (Conditional Mean Substitution)
      \begin{itemize}
      \item Replace $Y_{mis}$ with $\widehat{Y}_{mis}$ from some regression
        equation
        \begin{itemize}
        \item Positively biases regression slopes and correlations
        \item Inflates measures of linear association
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{
        
        <<echo = FALSE>>=
        p1
        @ 
        
      }
      
      \only<2>{

        <<echo = FALSE, cache = TRUE>>=
        miceD <- mice(data      = diabetes2[ , c("bmi", "glu")],
                      m         = 1,
                      maxit     = 1,
                      method    = "norm.predict",
                      printFlag = FALSE)

        datD0 <- datD <- complete(miceD, 1)
        datD[!m, ] <- NA
        
        p2 <- p1 + geom_point(data = datD,
                              mapping = aes(y = glu, x = bmi),
                              colour = "red")
        p2
        @

      }
      \only<3>{
        
        <<echo = FALSE, cache = TRUE>>=
        p2 + geom_smooth(data    = diabetes1,
                         mapping = aes(y = glu, x = bmi),
                         method  = "lm",
                         color   = "blue",
                         se      = FALSE) +
            geom_smooth(data    = datD0,
                        mapping = aes(y = glu, x = bmi),
                        method  = "lm",
                        color   = "red",
                        se      = FALSE)
        @

      }
      
    \end{column}
  \end{columns}
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
  <<>>=
  imputed <- mice(data      = diabetes2, 
                  m         = 1, 
                  maxit     = 1,
                  printFlag = FALSE,
                  method    = "norm.predict") %>% 
      complete(1)
  @ 
  
\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  imputed %>% select(bmi, glu, bp) %>% cor()
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  mean(diabetes1$glu)
  mean(imputed$glu, na.rm = TRUE)
  var(diabetes1$glu)
  var(imputed$glu, na.rm = TRUE)
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
  s2 <- lm(glu ~ bmi + bp + age, data = imputed) %>% summary()
  
  s1$r.squared
  s2$r.squared
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1$coef
  s2$coef
  @
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  \begin{center}
    \ovalbox{General Issues with Deletion-Based Methods}
  \end{center}

  \begin{itemize}
  \item Biased parameter estimates unless data are MCAR
  \item Generalizability issues
  \end{itemize}

  \va

  \begin{center}
    \ovalbox{General Issues with Simple Single Imputation Methods}
  \end{center}

  \begin{itemize}
  \item Biased parameter estimates even when data are MCAR
  \item Attenuates variability in any treated variables
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Bad Methods (These almost never work)}

  Averaging Available Items (Person-Mean Imputation)
  \begin{itemize}
  \item Compute aggregate scores using only available values
    \begin{itemize}
    \item Missing data must be MCAR
    \item Each item must contributes equally to the aggregate score
    \end{itemize}
  \end{itemize}

  \vb

  Last Observation Carried Forward (LOCF)
  \begin{itemize}
  \item Replace post-dropout values with the most recent observed value
    \begin{itemize}
    \item Assume that dropouts would maintain their last known values
    \item Attenuates estimates of growth/development
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}{LOCF}
  
  <<echo = FALSE, cache = TRUE>>=
  ## Simulate some longitudinal data with random slopes:
  n1 <- 5
  n2 <- 50
  
  s     <- 1.0
  gamma <- c(1.5, 1.25)
  tau   <- matrix(c(1.0, -0.3, -0.3, 1.0), 2, 2)
  
  U    <- rmvnorm(n2, gamma, tau)
  time <- matrix(1:n1 - 1)
  tmp  <- U[ , 1] + U[ , 2] %*% t(time)
  
  dat1 <- dat2 <- dat3 <-
      data.frame(y = as.numeric(tmp) + rnorm(n1 * n2, 0, s),
                 t = rep(0:(n1 - 1), each = n2),
                 id = rep(1:n2, n1)
                 ) %>%
      arrange(id)
  
  ## Apply random attrition:
  dat2$y <- dat1 %$% tapply(y, id, attrit, pComp = 0.25) %>% unlist()
  
  ## Treat attrition with LOCF:
  dat3$y <- dat2 %$% tapply(y, id, locf) %>% unlist()
  
  ## Create some missingness indicators for plotting purposes:
  dat3$m  <- is.na(dat2$y)
  dat3$m2 <- dat3 %$% tapply(m,
                             id,
                             function(x) {
                                 tmp <- (which(x) - 1)[1]
                                 x[tmp] <- TRUE
                                 x
                             }
                             ) %>% unlist()
  
  p00 <- ggplot(data = dat1, mapping = aes(y = y, x = t)) +
      ylab("Y") +
      xlab("Time") +
      theme_classic() +
      theme(text = element_text(size = 8, family = "Courier"),
            plot.title = element_text(face = "bold", hjust = 0.5),
            axis.title = element_blank(),
            legend.position = "none") +
      ylim(range(dat1$y))
  
  p01 <- p00 + scale_color_manual(values = c("black", "red"))
  @ 
  
  \only<1>{
    
    <<echo = FALSE, cache = TRUE, fig.asp = 0.5>>=
    ggarrange(
        p00 + 
        geom_line(aes(group = id), alpha = 0.3) + 
        geom_point(size = 0.75) +
        ggtitle("Fully Observed Data"),
        
        p00 + 
        geom_line(data = dat2, mapping = aes(group = id), alpha = 0.3) +
        geom_point(data = dat2, size = 0.75) +
        ggtitle("Data with Attrition") +
        theme(axis.text.y = element_blank()),
        
        ncol = 2) %>%
        annotate_figure(left = text_grob("Y", 
                                         family = "Courier", 
                                         size = 10,
                                         rot = 90),
                        bottom = text_grob("Time", family = "Courier", size = 10)
                        )
    @
    
  }
  
  \only<2>{
    
    <<echo = FALSE, cache = TRUE, fig.asp = 0.5>>=
    ggarrange(
        p01 + 
        geom_line(data = dat3, aes(group = id, color = m2), alpha = 0.3) +
        geom_point(data = dat3, aes(color = m), size = 0.75) +
        ggtitle("Data Treated with LOCF"),
        
        p01 + 
        geom_line(data = dat3, aes(group = id, color = m2), alpha = 0.1) +
        geom_point(data = dat3, aes(color = m), alpha = 0.1, size = 0.75) +
        geom_smooth(data = dat3,
                    method = "lm",
                    se = FALSE,
                    color = "red",
                    size = 1) +
        geom_smooth(data = dat1,
                    method = "lm",
                    se = FALSE,
                    color = "black",
                    size = 1) +
        ggtitle("Correct vs. Imputed Trends") +
        theme(axis.text.y = element_blank()),
        
        ncol = 2) %>%
        annotate_figure(left = text_grob("Y", 
                                         family = "Courier", 
                                         size = 10,
                                         rot = 90),
                        bottom = text_grob("Time", family = "Courier", size = 10)
                        )
    @
    
  }
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
  <<>>=
  ## Fit some multilevel regression models
  fit1 <- lmer(y ~ t + (t | id), data = dat1) # Full data
  fit2 <- lmer(y ~ t + (t | id), data = dat3) # LOCF data
  @ 
  
  <<echo = FALSE, fig.asp = 0.5>>=
  rf1 <- ranef(fit1)[[1]]
  rf2 <- ranef(fit2)[[1]]

  rf <- data.frame(Data = rep(c("Full", "LOCF"), each = nrow(rf1)),
                   x = c(rf1$t, rf2$t)
                   )

  ff1 <- coef(fit1)[[1]]
  ff2 <- coef(fit2)[[1]]

  ff <- data.frame(Data = rep(c("Full", "LOCF"), each = nrow(ff1)),
                   x = c(ff1$t, ff2$t)
                   )
  
  ggarrange(
      ggplot(data = rf, mapping = aes(x = x, color = Data)) + 
      geom_density() +
      ggtitle("Random Effects") +
      scale_color_manual(values = c("black", "red")) +
      theme_classic() +
      theme(text = element_text(size = 8, family = "Courier"),
            plot.title = element_text(face = "bold", hjust = 0.5),
            axis.title = element_blank()
            ),
    
      ggplot(data = ff, mapping = aes(x = x, color = Data)) + 
      geom_density() +
      ggtitle("Fixed Effects") +
      scale_color_manual(values = c("black", "red")) +
      theme_classic() +
      theme(text = element_text(size = 8, family = "Courier"),
            plot.title = element_text(face = "bold", hjust = 0.5),
            axis.title = element_blank(),
            axis.text.y = element_blank()
            ),
      
      ncol = 2,
      common.legend = TRUE,
      legend = "right") %>%
      annotate_figure(left = text_grob("Density", 
                                       family = "Courier", 
                                       size = 10,
                                       rot = 90),
                      bottom = text_grob("Effect", family = "Courier", size = 10)
                      )
  @
  
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{OK Methods (These sometimes work)}

  \begin{columns}
    \begin{column}{0.5\textwidth}

      Stochastic Regression Imputation
      \vc
      \begin{itemize}
      \item Fill $Y_{mis}$ with $\widehat{Y}_{mis}$ plus some random noise.
        \vc
        \begin{itemize}
        \item Produces unbiased parameter estimates and predictions
          \vc
        \item Computationally efficient
          \vc
        \item Attenuates standard errors
          \vc
        \item Makes CIs and prediction intervals too narrow
        \end{itemize}
      \end{itemize}

    \end{column}
    \begin{column}{0.5\textwidth}

      \only<1>{
        
        <<echo = FALSE>>=
        p1
        @ 
        
      }
      \only<2>{
        
        <<echo = FALSE, cache = TRUE>>=
        miceS <- mice(data      = diabetes2[ , c("bmi", "glu")],
                      m         = 1,
                      maxit     = 1,
                      method    = "norm.nob",
                      printFlag = FALSE)
        
        datS0 <- datS <- complete(miceS, 1)
        datS[!m, ] <- NA
        
        p2 <- p1 + geom_point(data = datS,
                              mapping = aes(y = glu, x = bmi),
                              colour = "red")
        p2
        @
        
      }
      \only<3>{
        
        <<echo = FALSE, cache = TRUE>>=
        p2 + geom_smooth(data    = diabetes1,
                         mapping = aes(y = glu, x = bmi),
                         method  = "lm",
                         color   = "blue",
                         se      = FALSE) +
            geom_smooth(data    = datD0,
                        mapping = aes(y = glu, x = bmi),
                        method  = "lm",
                        color   = "red",
                        se      = FALSE)
        @
        
      }
      
    \end{column}
  \end{columns}

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[fragile]{Example}
 
  <<>>=
  imputed <- mice(data      = diabetes2, 
                  m         = 1, 
                  maxit     = 1,
                  printFlag = FALSE,
                  method    = "norm.nob") %>% 
      complete(1)
  @ 

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  imputed %>% select(bmi, glu, bp) %>% cor()
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  mean(diabetes1$glu)
  mean(imputed$glu)
  var(diabetes1$glu)
  var(imputed$glu)
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1 <- lm(glu ~ bmi + bp + age, data = diabetes1) %>% summary()
  s2 <- lm(glu ~ bmi + bp + age, data = imputed) %>% summary()

  s1$r.squared
  s2$r.squared
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  s1$coef
  s2$coef
  @
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}{OK Methods (These sometimes work)}

  Nonresponse Weighting
  \vc
  \begin{itemize}
  \item Weight the observed cases to correct for nonresponse bias
    \vc
    \begin{itemize}
    \item Popular in survey research and official statistics
      \vc
    \item Only worth considering with \emph{Unit Nonresponse}
      \vc
    \item Doesn't make any sense with \emph{Item Nonresponse}
    \end{itemize}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Good Methods (These almost always work)}

  Multiple Imputation (MI)
  \vc
  \begin{itemize}
  \item Replace the missing values with $M$ plausible estimates
    \vc
    \begin{itemize}
    \item Essentially, a repeated application of stochastic regression
      imputation (with a particular type of regression model)
      \vc
    \item Produces unbiased parameter estimates and predictions
      \vc
    \item Produces ``correct'' standard errors, CIs, and prediction intervals
      \vc
    \item Very, very flexible
      \vc
    \item Computationally expensive
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[allowframebreaks, fragile]{Good Methods (These almost always
    work)}

  What happens when we apply MI to our previous MAR example?
  <<>>=
  ## Estimate imputation model:
  miceOut <- mice(data      = marData,
                  m         = 25,
                  maxit     = 1,
                  method    = "norm",
                  printFlag = FALSE)
  
  ## Estimate and pool M correlations:
  with(miceOut, cor(y, x))$analyses %>% unlist() %>% mean()
  @
  
  The MI-based parameter estimate looks good.
  \begin{itemize}
  \item MI produces unbiased estimates of the parameter when data are MAR.
  \end{itemize}

  \pagebreak
  
  <<echo = FALSE, out.width = "65%">>=
  impX <- impY <- list()
  for(m in 1 : miceOut$m) {
      tmp       <- density(complete(miceOut, m)$y)
      impX[[m]] <- tmp$x
      impY[[m]] <- tmp$y
  }
  
  pDat <- data.frame(x = unlist(impX),
                     y = unlist(impY),
                     g = rep(1 : miceOut$m, each = length(impX[[1]])),
                     c = "MAR w/ MI")
  
  pDat <- rbind.data.frame(pDat,
                           data.frame(x = yDen$x, 
                                      y = yDen$y, 
                                      g = miceOut$m + 1, 
                                      c = "Complete")
                           )
  
  ggplot(data    = pDat, 
         mapping = aes(x = x, y = y, color = c, group = g, size = c)
         ) +
      geom_line() +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      ylab("Density") +
      xlab("Value of Y") +
      scale_color_manual(values = c("black", "red")) +
      scale_size_manual(values = c(1, 0.5)) +
      theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Good Methods (These \emph{almost} always work)}
  
  What about applying MI to our MNAR example?
  <<>>=
  ## Estimate imputation model:
  miceOut <- mice(data      = mnarData,
                  m         = 25,
                  maxit     = 1,
                  method    = "norm",
                  printFlag = FALSE)
  
  ## Estimate and pool M correlations:
  with(miceOut, cor(y, x))$analyses %>% unlist() %>% mean()
  @
  
  The MI-based parameter estimate is still biased.
  \begin{itemize}
  \item MI cannot correct bias in parameter estimates when data are MNAR.
  \end{itemize}
  
  \pagebreak
  
  <<echo = FALSE, out.width = "65%">>=
  mnarDen <- mnarData %$% density(y, na.rm = TRUE)
  
  impX <- impY <- list()
  for(m in 1 : miceOut$m) {
      tmp       <- density(complete(miceOut, m)$y)
      impX[[m]] <- tmp$x
      impY[[m]] <- tmp$y
  }
  
  pDat <- data.frame(x = unlist(impX),
                     y = unlist(impY),
                     g = rep(1:miceOut$m, each = length(impX[[1]])),
                     c = "MNAR w/ MI")
  
  pDat <- rbind.data.frame(pDat,
                           data.frame(x = mnarDen$x, 
                                      y = mnarDen$y, 
                                      g = miceOut$m + 1, 
                                      c = "MNAR w/ Deletion"),
                           data.frame(x = yDen$x, 
                                      y = yDen$y, 
                                      g = miceOut$m + 2,
                                      c = "Complete")
                           )
  
  ggplot(data = pDat, mapping = aes(x = x, y = y, color = c, group = g, size = c)) +
      geom_line() +
      theme_classic() +
      theme(text = element_text(family = "Courier", size = 16)) +
      ylab("Density") +
      xlab("Value of Y") +
      scale_color_manual(values = c("black", "blue", "red")) +
      scale_size_manual(values = c(1, 1, 0.5)) +
      theme(legend.position = c(0.8, 0.95), legend.title = element_blank())
  @
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%


\begin{frame}[fragile]{Example}
 
  <<>>=
  miceOut <- mice(data      = diabetes2, 
                  m         = 25, 
                  maxit     = 1,
                  printFlag = FALSE,
                  method    = "norm")
  @ 

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cor()
  pooledCorMat(miceOut, c("bmi", "glu", "bp"))
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  mean(diabetes1$glu)
  with(miceOut, mean(glu))$analyses %>% unlist() %>% mean()
  var(diabetes1$glu)
  with(miceOut, var(glu))$analyses %>% unlist() %>% mean()
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  fit1 <- lm(glu ~ bmi + bp + age, data = diabetes1)
  fit2 <- with(miceOut, lm(glu ~ bmi + bp + age))
  
  summary(fit1)$r.squared
  pool.r.squared(fit2)
  @ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  summary(fit1)$coef
  pool(fit2) %>% summary() %>% select(-df)
  @
  
\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Good Methods (These almost always work)}

  Bayesian Modeling
  \vc
  \begin{itemize}
  \item Treat missing values as just another parameter to be estimated
    \vc
    \begin{itemize}
    \item Models can be directly estimated in the presence of missing data
      \begin{itemize}
      \item Essentially, runs MI behind-the-scenes during model estimation
      \end{itemize}
      \vc
    \item The predictors of nonresponse must be included in the model, somehow
      \vc
    \item Computationally expensive
    \end{itemize}
  \end{itemize}

  \pagebreak

  Full Information Maximum Likelihood (FIML)
  \vc
  \begin{itemize}
  \item Adjust the objective function to only consider the observed parts of the
    data
    \vc
    \begin{itemize}
    \item Models are directly estimated in the presence of missing data
      \vc
    \item The predictors of nonresponse must be included in the model, somehow
      \vc
    \item Unless you write your own optimization program, FIML is only available
      for certain types of models
      \vc
    \item In linear regression models, FIML cannot treat missing data on
      predictors (if the predictors are taken as fixed)
    \end{itemize}
  \end{itemize}

\end{frame}

\watermarkoff %----------------------------------------------------------------%

\begin{frame}[fragile]{Example}
  
  <<>>=
  fit <- diabetes2 %>% 
      select(bmi, glu, bp) %>% 
      lavCor(missing = "fiml", output = "sampstat")
  
  mean(diabetes1$glu)
  fit$mean["glu"]
  @   

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  diabetes1 %>% select(bmi, glu, bp) %>% cov()
  fit$cov
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  mod <- "glu ~ 1 + bmi + bp + age"
  fit <- sem(mod, data = diabetes2, missing = "fiml")
  
  summary(fit1)$r.squared
  inspect(fit, "r2")
  @

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Example}

  <<>>=
  summary(fit1)$coef %>% round(3)
  parameterEstimates(fit, ci = FALSE)[1:4, ]
  @

\end{frame}

\watermarkon %-----------------------------------------------------------------%

\begin{frame}[allowframebreaks]{References}

  \bibliographystyle{apacite}
  \bibliography{../../../bibtex/winter_school_refs.bib}

\end{frame}

%------------------------------------------------------------------------------%

\end{document}
